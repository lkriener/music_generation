{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_RNN_pianorolls_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mEpS7y23emOr","colab_type":"code","colab":{}},"source":["#rm -r *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557735083676,"user_tz":-120,"elapsed":7455,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"kfpjADwL4oUx","outputId":"04fa8a9c-f4c5-4955-e304-c50d8bc64c91","colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["# Uncomment the line below and run this cell to get your data from github into colab (only runnable in colab, not ordinary jupyter notebook):\n","! git clone https://github.com/lkriener/music_generation.git && mv music_generation/* . && rm music_generation -r "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'music_generation'...\n","remote: Enumerating objects: 500, done.\u001b[K\n","remote: Counting objects: 100% (500/500), done.\u001b[K\n","remote: Compressing objects: 100% (457/457), done.\u001b[K\n","remote: Total 500 (delta 68), reused 465 (delta 36), pack-reused 0\n","Receiving objects: 100% (500/500), 427.98 KiB | 14.27 MiB/s, done.\n","Resolving deltas: 100% (68/68), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557735096663,"user_tz":-120,"elapsed":8741,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"sLhyMMRj4tNz","outputId":"383a73d9-1275-45aa-f84b-39404255841a","colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["# Uncomment line to install requirements\n","! pip install -r colab_requirements.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pygame==1.9.6 (from -r colab_requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n","\u001b[K     |████████████████████████████████| 11.4MB 2.7MB/s \n","\u001b[?25hCollecting py_midicsv==1.9.0 (from -r colab_requirements.txt (line 3))\n","  Downloading https://files.pythonhosted.org/packages/1f/eb/3133f65bd34dafcbae37508d290ebf540832430cbe2aef23629cc6a6197f/py_midicsv-1.9.0-py3-none-any.whl\n","Collecting pypianoroll==0.5.0 (from -r colab_requirements.txt (line 4))\n","  Downloading https://files.pythonhosted.org/packages/aa/33/fa38c07909e425add987146cb0f8d5ad80262f6a72cc820bf7e5f690d527/pypianoroll-0.5.0.tar.gz\n","Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.12.0)\n","Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.16.3)\n","Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.2.1)\n","Requirement already satisfied: pretty_midi<1.0,>=0.2.8 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (0.2.8)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/dist-packages (from pretty_midi<1.0,>=0.2.8->pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.2.6)\n","Building wheels for collected packages: pypianoroll\n","  Building wheel for pypianoroll (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/ed/f6/fb/5d070524ecf7ba9ed201247a293c01945cfd7f840f8ef338c0\n","Successfully built pypianoroll\n","Installing collected packages: pygame, py-midicsv, pypianoroll\n","Successfully installed py-midicsv-1.9.0 pygame-1.9.6 pypianoroll-0.5.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EH9lnM84OBTV","colab_type":"text"},"source":["# Music generation using note-to-note LSTMs \n","In this part, we will try to generate melodies from the same dataset (Bach Chorals) using recurrent neural networks (RNN) with long short term memory units (LSTM) as in the tutorial 08 of the class, based on the two following blog posts:\n","\n","- http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n","- https://towardsdatascience.com/writing-like-shakespeare-with-machine-learning-in-pytorch-d77f851d910c\n","\n","The idea would be to extend the character-to-character LSTM network to midi files. We will also use another representation of the data, namely 'pianorolls', where a single melody is stored in a matrix with the x-axis for time and the y-axis for the pitch. This is one of the most frequent representations used, although it has some limitations. For instance, there is no way to differentiate between a long note (1 half-note) and 4 short-ones (4 eight-notes). However, it brings a considerable advantage compared to the previous used representations as it can store rhythm, depending on the chosen time-step. \n","\n","Moreover, each possible note is considered as a distinct element of a vocabulary. We will then use $N$ input nodes, where $N$ is the size of the vocabulary (i.e., the number of distinct notes, including silences). \n","Thus, these pianorolls arrays will be converted into one-hot vectors containing the corresponding pitch (or silence, represented by 0) for each time step, and will be fed to the RNN network defined below. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HygKqpcn-_Ih"},"source":["## Test of pypianoroll library\n","We will first use the pypianoroll library - https://salu133445.github.io/pypianoroll/ - to convert a midi file into a multitrack object, get the soprano track, transpose it to C major, create a new multitrack object out of it, and finally write it to a new midi file. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DaVKNWw4lLr","outputId":"32aa011e-9184-4b4f-9b0d-1b9143f8ad16","executionInfo":{"status":"ok","timestamp":1557735104467,"user_tz":-120,"elapsed":4917,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import src.midi_utils as midi_utils\n","import pygame\n","from pypianoroll import Multitrack, Track\n","import pypianoroll\n","import os\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pygame 1.9.6\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n","Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n","Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n","Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1826816/45929032 bytes (4.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5660672/45929032 bytes (12.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9322496/45929032 bytes (20.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13180928/45929032 bytes (28.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17039360/45929032 bytes (37.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20701184/45929032 bytes (45.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24535040/45929032 bytes (53.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28352512/45929032 bytes (61.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32235520/45929032 bytes (70.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35971072/45929032 bytes (78.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39837696/45929032 bytes (86.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43393024/45929032 bytes (94.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n","  Done\n","File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IugBxMoP4lLy","colab":{}},"source":["try:\n","    home_dir\n","except NameError:\n","    home_dir = os.getcwd()\n","\n","os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BrAiT6ot4lL2","colab":{}},"source":["from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n","from torch.utils.data import DataLoader\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","feature_scaler = StandardScaler()\n","label_scaler = StandardScaler()\n","\n","# iterate over all midi files of folder\n","import glob\n","import os\n","import numpy as np\n","\n","try:\n","    home_dir\n","except NameError:\n","    home_dir = os.getcwd()\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zVNrDFfI4lL4","colab":{}},"source":["def get_track_transposed(midi_filename, voice, beat_resolution, transpose = True):\n","    csv_text = midi_utils.load_to_csv(midi_filename)\n","    # get semitones to C major \n","    semitones,_ = midi_utils.get_semitones_to_C(csv_text)\n","    # get multitrack object from midi \n","    multitrack = pypianoroll.parse(midi_filename, beat_resolution=beat_resolution)\n","    # get the voice track \n","    if transpose: \n","        track = pypianoroll.transpose(multitrack.tracks[voice], -semitones)\n","    else:\n","        track = multitrack.tracks[voice]\n","    return track\n","\n","\n","def get_all_pianorolls(voice, home_dir, beat_resolution=4):\n","    '''\n","    Returns a large concatenated pianoroll from all Bach Chorals midi files\n","    :voice: 0 = soprano, 1 = alto, 2 = tenor, 3 = bass \n","    :home_dir: home directory we extract midi files from\n","    :beat_resolution: minimal pianoroll time step. Default 4=sixteenth\n","    :return:\n","    '''\n","  \n","    list_pianorolls = []\n","    os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir\n","  \n","    for midi_file in glob.glob(\"*.mid\"):\n","        #print(midi_file)\n","        track = get_track_transposed(midi_file, voice, beat_resolution=beat_resolution)\n","        # get the flattened representation of pianoroll\n","        pianoroll_flattened = midi_utils.flatten_one_hot_pianoroll(track.pianoroll)\n","        # add it to the global list of all tracks\n","        list_pianorolls.append(pianoroll_flattened)\n","        \n","    # convert into an array \n","    all_pianorolls = np.concatenate(list_pianorolls)\n","    \n","    return all_pianorolls\n","\n","def get_extremum_pitches(list_pianorolls):\n","    '''\n","    Return extremum pitches and pitch dictionnary of a given pitch sequence\n","    :list_pianorolls: list containing pianorolls sequence\n","    :return:\n","    '''\n","    list_min = []\n","    list_max = []\n","    \n","    for pianoroll in list_pianorolls:\n","        minimum  = np.min(pianoroll[np.nonzero(pianoroll)])\n","        maximum = np.max(pianoroll)\n","        list_min.append(minimum)\n","        list_max.append(maximum)\n","    global_lower = int(min(list_min))\n","    global_upper = int(max(list_max))\n","    n_notes = global_upper - global_lower + 2 \n","    \n","    return global_lower, global_upper, n_notes\n","        \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557736557625,"user_tz":-120,"elapsed":7721,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"8EnWFvKA4lL7","outputId":"66c9c145-8d86-42c4-d8ce-ece64a7b1c26","colab":{"base_uri":"https://localhost:8080/","height":6137}},"source":["# get lower and upper bounds \n","voice = 0 \n","all_pianorolls = get_all_pianorolls(voice, home_dir, beat_resolution=4)\n","global_lower, global_upper, n_notes = get_extremum_pitches([all_pianorolls])\n","print('Global lower note : '+ str(global_lower))\n","print('Global upper note : '+ str(global_upper))\n","print('Number of notes : '+ str(n_notes))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["bwv245.5.mid\n","bwv2.6.mid\n","bwv266.mid\n","bwv364.mid\n","bwv183.5.mid\n","bwv397.mid\n","bwv197.10.mid\n","bwv337.mid\n","bwv187.7.mid\n","bwv277.mid\n","bwv339.mid\n","bwv6.6.mid\n","bwv197.7-a.mid\n","bwv310.mid\n","bwv270.mid\n","bwv410.mid\n","bwv154.3.mid\n","bwv248.35-3.mid\n","bwv245.37.mid\n","bwv3.6.mid\n","bwv9.7.mid\n","bwv144.3.mid\n","bwv153.1.mid\n","bwv256.mid\n","bwv14.5.mid\n","bwv244.40.mid\n","bwv36.8-2.mid\n","bwv113.8.mid\n","bwv101.7.mid\n","bwv330.mid\n","bwv380.mid\n","bwv178.7.mid\n","bwv227.11.mid\n","bwv159.5.mid\n","bwv258.mid\n","bwv293.mid\n","bwv77.6.mid\n","bwv87.7.mid\n","bwv56.5.mid\n","bwv360.mid\n","bwv120.6.mid\n","bwv36.4-2.mid\n","bwv417.mid\n","bwv177.5.mid\n","bwv381.mid\n","bwv373.mid\n","bwv157.5.mid\n","bwv267.mid\n","bwv322.mid\n","bwv114.7.mid\n","bwv325.mid\n","bwv244.25.mid\n","bwv284.mid\n","bwv190.7.mid\n","bwv244.62.mid\n","bwv416.mid\n","bwv117.4.mid\n","bwv406.mid\n","bwv280.mid\n","bwv89.6.mid\n","bwv283.mid\n","bwv245.15.mid\n","bwv194.6.mid\n","bwv72.6.mid\n","bwv422.mid\n","bwv430.mid\n","bwv145.5.mid\n","bwv245.26.mid\n","bwv84.5.mid\n","bwv180.7.mid\n","bwv248.5.mid\n","bwv345.mid\n","bwv65.7.mid\n","bwv365.mid\n","bwv370.mid\n","bwv92.9.mid\n","bwv248.53-5.mid\n","bwv399.mid\n","bwv341.mid\n","bwv434.mid\n","bwv420.mid\n","bwv313.mid\n","bwv376.mid\n","bwv166.6.mid\n","bwv244.37.mid\n","bwv263.mid\n","bwv329.mid\n","bwv324.mid\n","bwv318.mid\n","bwv437.mid\n","bwv432.mid\n","bwv5.7.mid\n","bwv335.mid\n","bwv119.9.mid\n","bwv265.mid\n","bwv244.32.mid\n","bwv285.mid\n","bwv383.mid\n","bwv366.mid\n","bwv37.6.mid\n","bwv303.mid\n","bwv408.mid\n","bwv271.mid\n","bwv294.mid\n","bwv403.mid\n","bwv302.mid\n","bwv336.mid\n","bwv64.2.mid\n","bwv126.6.mid\n","bwv127.5.mid\n","bwv349.mid\n","bwv396.mid\n","bwv125.6.mid\n","bwv344.mid\n","bwv69.6-a.mid\n","bwv312.mid\n","bwv371.mid\n","bwv426.mid\n","bwv244.54.mid\n","bwv333.mid\n","bwv387.mid\n","bwv395.mid\n","bwv276.mid\n","bwv81.7.mid\n","bwv400.mid\n","bwv288.mid\n","bwv431.mid\n","bwv78.7.mid\n","bwv436.mid\n","bwv244.3.mid\n","bwv287.mid\n","bwv435.mid\n","bwv248.46-5.mid\n","bwv245.17.mid\n","bwv377.mid\n","bwv342.mid\n","bwv402.mid\n","bwv419.mid\n","bwv350.mid\n","bwv48.3.mid\n","bwv245.11.mid\n","bwv73.5.mid\n","bwv257.mid\n","bwv55.5.mid\n","bwv18.5-lz.mid\n","bwv289.mid\n","bwv304.mid\n","bwv140.7.mid\n","bwv359.mid\n","bwv176.6.mid\n","bwv260.mid\n","bwv255.mid\n","bwv245.3.mid\n","bwv272.mid\n","bwv305.mid\n","bwv139.6.mid\n","bwv321.mid\n","bwv44.7.mid\n","bwv123.6.mid\n","bwv334.mid\n","bwv362.mid\n","bwv279.mid\n","bwv121.6.mid\n","bwv389.mid\n","bwv278.mid\n","bwv404.mid\n","bwv331.mid\n","bwv332.mid\n","bwv405.mid\n","bwv169.7.mid\n","bwv401.mid\n","bwv13.6.mid\n","bwv244.17.mid\n","bwv259.mid\n","bwv104.6.mid\n","bwv115.6.mid\n","bwv64.8.mid\n","bwv301.mid\n","bwv343.mid\n","bwv248.64-s.mid\n","bwv227.1.mid\n","bwv42.7.mid\n","bwv295.mid\n","bwv291.mid\n","bwv423.mid\n","bwv262.mid\n","bwv67.7.mid\n","bwv415.mid\n","bwv229.2.mid\n","bwv70.7.mid\n","bwv102.7.mid\n","bwv226.2.mid\n","bwv151.5.mid\n","bwv425.mid\n","bwv379.mid\n","bwv363.mid\n","bwv386.mid\n","bwv103.6.mid\n","bwv93.7.mid\n","bwv299.mid\n","bwv352.mid\n","bwv385.mid\n","bwv319.mid\n","bwv351.mid\n","bwv66.6.mid\n","bwv133.6.mid\n","bwv158.4.mid\n","bwv317.mid\n","bwv16.6.mid\n","bwv398.mid\n","bwv28.6.mid\n","bwv154.8.mid\n","bwv168.6.mid\n","bwv340.mid\n","bwv43.11.mid\n","bwv290.mid\n","bwv111.6.mid\n","bwv348.mid\n","bwv48.7.mid\n","bwv245.40.mid\n","bwv32.6.mid\n","bwv40.6.mid\n","bwv311.mid\n","bwv320.mid\n","bwv327.mid\n","bwv20.7.mid\n","bwv393.mid\n","bwv244.46.mid\n","bwv438.mid\n","bwv390.mid\n","bwv18.5-w.mid\n","bwv122.6.mid\n","bwv355.mid\n","bwv39.7.mid\n","bwv65.2.mid\n","bwv347.mid\n","bwv433.mid\n","bwv264.mid\n","bwv384.mid\n","bwv374.mid\n","bwv273.mid\n","bwv145-a.mid\n","bwv153.9.mid\n","bwv411.mid\n","bwv188.6.mid\n","bwv86.6.mid\n","bwv369.mid\n","bwv60.5.mid\n","bwv388.mid\n","bwv269.mid\n","bwv184.5.mid\n","bwv248.33-3.mid\n","bwv74.8.mid\n","bwv391.mid\n","bwv112.5.mid\n","bwv392.mid\n","bwv354.mid\n","bwv338.mid\n","bwv94.8.mid\n","bwv429.mid\n","bwv245.14.mid\n","bwv17.7.mid\n","bwv261.mid\n","bwv227.7.mid\n","bwv346.mid\n","bwv26.6.mid\n","bwv372.mid\n","bwv382.mid\n","bwv146.8.mid\n","bwv108.6.mid\n","bwv353.mid\n","bwv308.mid\n","bwv38.6.mid\n","bwv412.mid\n","bwv7.7.mid\n","bwv248.12-2.mid\n","bwv99.6.mid\n","bwv428.mid\n","bwv296.mid\n","bwv57.8.mid\n","bwv244.44.mid\n","bwv268.mid\n","bwv248.28.mid\n","bwv85.6.mid\n","bwv394.mid\n","bwv413.mid\n","bwv47.5.mid\n","bwv20.11.mid\n","bwv4.8.mid\n","bwv326.mid\n","bwv165.6.mid\n","bwv244.10.mid\n","bwv116.6.mid\n","bwv418.mid\n","bwv300.mid\n","bwv90.5.mid\n","bwv307.mid\n","bwv244.15.mid\n","bwv248.42-s.mid\n","bwv11.6.mid\n","bwv30.6.mid\n","bwv292.mid\n","bwv164.6.mid\n","bwv244.29-a.mid\n","bwv367.mid\n","bwv421.mid\n","bwv40.3.mid\n","bwv110.7.mid\n","bwv407.mid\n","bwv424.mid\n","bwv45.7.mid\n","bwv378.mid\n","bwv10.7.mid\n","bwv297.mid\n","bwv88.7.mid\n","bwv316.mid\n","bwv298.mid\n","bwv375.mid\n","bwv282.mid\n","bwv144.6.mid\n","bwv148.6.mid\n","bwv281.mid\n","bwv414.mid\n","bwv40.8.mid\n","bwv315.mid\n","bwv286.mid\n","bwv245.28.mid\n","bwv328.mid\n","bwv248.23-s.mid\n","bwv245.22.mid\n","bwv174.5.mid\n","bwv83.5.mid\n","bwv67.4.mid\n","bwv314.mid\n","bwv25.6.mid\n","bwv96.6.mid\n","bwv357.mid\n","bwv358.mid\n","bwv356.mid\n","bwv323.mid\n","bwv156.6.mid\n","bwv33.6.mid\n","bwv253.mid\n","bwv306.mid\n","bwv80.8.mid\n","bwv309.mid\n","bwv361.mid\n","bwv153.5.mid\n","bwv197.5.mid\n","bwv155.5.mid\n","bwv254.mid\n","bwv194.12.mid\n","bwv179.6.mid\n","bwv135.6.mid\n","bwv427.mid\n","bwv162.6-lpz.mid\n","bwv368.mid\n","Global lower note : 57\n","Global upper note : 83\n","Number of notes : 28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557735893582,"user_tz":-120,"elapsed":3759,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"P3Tts_gs4lL9","outputId":"a58a687c-5199-4f46-c51b-d8e8de534107","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["print(\"Pianoroll sequence of soprano :\")\n","print(all_pianorolls[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pianoroll sequence of soprano :\n","[ 0  0  0  0 70 70 70  0 70 70 68 68 66 66 66 66 68 68 68 68 70 70 68 68\n"," 66 66 66 66 65 65 65 65 63 63 63 63 70 70 70  0 70 70 70 70 68 68 68 68\n"," 73 73 73 73 70 70 68 68 66 66 66 66 68 68 68 68 70 70 70  0 70 70 72 72\n"," 73 73 73 73 75 75 77 77 78 78 78 78 77 77 77 77 75 75 75 75 74 74 74 74\n"," 75 75 75  0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rzfuMYvgZ6if","colab_type":"text"},"source":["In order to minimize the size of one-hot encode vectors, we restrict the pitches to values next to 0, using the minimum pitch found in the dataset. "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557735895623,"user_tz":-120,"elapsed":453,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"ayfyARad4lL_","outputId":"c0cdc6c4-5f48-4250-94ed-c067ac0f7c57","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# scale pianoroll to 0 \n","print(\"Pianoroll sequence of soprano scaled to 0:\")\n","all_pianorolls_scaled = midi_utils.scale_pianoroll(all_pianorolls, global_lower)\n","print(all_pianorolls_scaled[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pianoroll sequence of soprano scaled to 0:\n","[ 0  0  0  0 14 14 14  0 14 14 12 12 10 10 10 10 12 12 12 12 14 14 12 12\n"," 10 10 10 10  9  9  9  9  7  7  7  7 14 14 14  0 14 14 14 14 12 12 12 12\n"," 17 17 17 17 14 14 12 12 10 10 10 10 12 12 12 12 14 14 14  0 14 14 16 16\n"," 17 17 17 17 19 19 21 21 22 22 22 22 21 21 21 21 19 19 19 19 18 18 18 18\n"," 19 19 19  0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"42JsbRVtN7L-","colab_type":"text"},"source":["## Generation of a single voice"]},{"cell_type":"markdown","metadata":{"id":"7nbdxBCkXycc","colab_type":"text"},"source":["As a first attempt to generate a melody using LSTMs with pianorolls, we will simply try to generate a single voice (soprano, alto, tenor or bass), training the network on the whole midi file dataset concatenated into a long sequence of notes all translated to the same tonality (here, C Major or its relative A minor). The later operation will particularly facilitate learning on such a small dataset as all melodies will be rescaled to the same tonality, thus preventing abrupt changes among melody batches. "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557735897116,"user_tz":-120,"elapsed":430,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"b37NFyC-4lMB","outputId":"15259288-dadf-4c5a-fb68-7a75f0037d9e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Check if GPU is available\n","train_on_gpu = torch.cuda.is_available()\n","if(train_on_gpu):\n","    print('Training on GPU!')\n","else: \n","    print('No GPU available, training on CPU; consider making n_epochs very small.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on GPU!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mrVryIjJ4lMC"},"source":["### Define a LSTM network as for note-to-note melody generation\n","We now build a network to implement note-to-note melody generation using LSTMs units as well as drop-out of the output. This network is highly inspired from the Tutorial 08 of the class, by replacing characters by notes. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IPccoLL84lMD","colab":{}},"source":["# Declaring the model\n","class NoteRNN(nn.Module):\n","    \n","    def __init__(self, n_notes, n_hidden=256, n_layers=2,\n","                               drop_prob=0.2, lr=0.001):\n","        super().__init__()\n","        self.drop_prob = drop_prob\n","        self.n_layers = n_layers\n","        self.n_hidden = n_hidden\n","        self.lr = lr\n","        \n","        self.n_notes = n_notes \n","        #define the LSTM\n","        self.lstm = nn.LSTM(self.n_notes, n_hidden, n_layers, \n","                            dropout=drop_prob, batch_first=True)\n","        \n","        #define a dropout layer\n","        self.dropout = nn.Dropout(drop_prob)\n","        \n","        #define the final, fully-connected output layer\n","        self.fc = nn.Linear(n_hidden, self.n_notes)\n","      \n","    \n","    def forward(self, x, hidden):\n","        ''' Forward pass through the network. \n","            These inputs are x, and the hidden/cell state `hidden`. '''\n","                \n","        #get the outputs and the new hidden state from the lstm\n","        r_output, hidden = self.lstm(x, hidden)\n","        \n","        #pass through a dropout layer\n","        out = self.dropout(r_output)\n","        \n","        # Stack up LSTM outputs using view\n","        out = out.contiguous().view(-1, self.n_hidden)\n","        \n","        #put x through the fully-connected layer\n","        out = self.fc(out)\n","        \n","        # return the final output and the hidden state\n","        return out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n","                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n","        \n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GxUeYhz24lME"},"source":["## Training Code\n","\n","Time for training! We declare a function, where we define an optimizer (Adam) and loss (cross entropy). Then, training and validation data are separated and the hidden state of the RNN is initaliazed. Looping over the training melody batches, we use the functions `get_pianoroll_batches` and `one_hot_encode_batch` in order to build batches and feed them to the network input. This function is also adapted to harmonization that will be defined below. \n","\n","Every once a while, we generate some loss statistics (training loss and validation loss) to let us know if the model is training correctly."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ySgtX9jT4lME","colab":{}},"source":["# Declaring the train method\n","def train(net, data, data2=None, mode=\"melody_generation\", epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n","    ''' Training a network \n","\n","        net: NoteRNN network\n","        data: text data to train the network\n","        epochs: Number of epochs to train\n","        batch_size: Number of mini-sequences per mini-batch, aka batch size\n","        seq_length: Number of character steps per mini-batch\n","        lr: learning rate\n","        clip: gradient clipping\n","        val_frac: Fraction of data to hold out for validation\n","        print_every: Number of steps for printing training and validation loss\n","    \n","    '''\n","    net.train()\n","    \n","    opt = torch.optim.Adam(net.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # create training and validation data\n","    val_idx = int(len(data)*(1-val_frac))\n","    data, val_data = data[:val_idx], data[val_idx:]\n","    if mode == \"harmonization\":\n","        data2, val_data2 = data2[:val_idx], data2[val_idx:]\n","    \n","    if(train_on_gpu):\n","        net.cuda()\n","        \n","    counter = 0\n","    n_notes = net.n_notes \n","    for e in range(epochs):\n","        # initialize hidden state\n","        h = net.init_hidden(batch_size)\n","        \n","        if mode == \"melody_generation\":\n","            batch_generator = midi_utils.get_pianoroll_batches(data, batch_size, seq_length)\n","        elif mode == \"harmonization\":\n","            batch_generator = midi_utils.get_pianoroll_batches_harmonization(data, data2, batch_size, seq_length)\n","        for x, y in batch_generator:\n","            counter += 1\n","            \n","            # One-hot encode our data and make them Torch tensors\n","            x = midi_utils.one_hot_encode_batch(x, n_notes)\n","            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n","            if(train_on_gpu):\n","                inputs, targets = inputs.cuda(), targets.cuda()\n","\n","            # Creating new variables for the hidden state, otherwise\n","            # we'd backprop through the entire training history\n","            h = tuple([each.data for each in h])\n","\n","            # zero accumulated gradients\n","            net.zero_grad()\n","            \n","            # get the output from the model\n","            output, h = net(inputs, h)\n","            # calculate the loss and perform backprop\n","            loss = criterion(output, targets.view(batch_size*seq_length).long())\n","            loss.backward()\n","            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","            nn.utils.clip_grad_norm_(net.parameters(), clip)\n","            opt.step()\n","            \n","            # loss stats\n","            if counter % print_every == 0:\n","                # Get validation loss\n","                val_h = net.init_hidden(batch_size)\n","                val_losses = []\n","                net.eval()\n","                \n","                if mode == \"melody_generation\":\n","                    batch_generator_val = midi_utils.get_pianoroll_batches(val_data, batch_size, seq_length)\n","                elif mode == \"harmonization\":\n","                    batch_generator_val = midi_utils.get_pianoroll_batches_harmonization(val_data, val_data2, batch_size, seq_length)\n","                for x, y in batch_generator_val:\n","                    # One-hot encode our data and make them Torch tensors\n","                    x = midi_utils.one_hot_encode_batch(x, n_notes)\n","                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n","                    \n","                    # Creating new variables for the hidden state, otherwise\n","                    # we'd backprop through the entire training history\n","                    val_h = tuple([each.data for each in val_h])\n","                    \n","                    inputs, targets = x, y\n","                    if(train_on_gpu):\n","                        inputs, targets = inputs.cuda(), targets.cuda()\n","\n","                    output, val_h = net(inputs, val_h)\n","                    val_loss = criterion(output, targets.contiguous().view(batch_size*seq_length).long())\n","                \n","                    val_losses.append(val_loss.item())\n","                \n","                net.train() # reset to train mode after iterationg through validation data\n","                \n","                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                      \"Step: {}...\".format(counter),\n","                      \"Loss: {:.4f}...\".format(loss.item()),\n","                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_Gr3LZSO4lMF","outputId":"92e9db52-63b5-4a4a-e9c2-5d55c1597df2","executionInfo":{"status":"ok","timestamp":1557751901275,"user_tz":-120,"elapsed":44868,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["# Define and print the net\n","n_hidden=128\n","n_layers=3\n","\n","net = NoteRNN(n_notes, n_hidden, n_layers)\n","print(net)\n","\n","# Declaring the hyperparameters\n","batch_size = 32\n","seq_length = 100\n","n_epochs = 20 # start smaller if you are just testing initial behavior\n","\n","# train the model\n","train(net, all_pianorolls_scaled, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"],"execution_count":204,"outputs":[{"output_type":"stream","text":["NoteRNN(\n","  (lstm): LSTM(50, 128, num_layers=3, batch_first=True, dropout=0.3)\n","  (dropout): Dropout(p=0.3)\n","  (fc): Linear(in_features=128, out_features=50, bias=True)\n",")\n","Epoch: 2/20... Step: 50... Loss: 2.9264... Val Loss: 2.7865\n","Epoch: 4/20... Step: 100... Loss: 2.9130... Val Loss: 2.7793\n","Epoch: 6/20... Step: 150... Loss: 2.7743... Val Loss: 2.6484\n","Epoch: 8/20... Step: 200... Loss: 2.5160... Val Loss: 2.4050\n","Epoch: 10/20... Step: 250... Loss: 2.3035... Val Loss: 2.2073\n","Epoch: 12/20... Step: 300... Loss: 2.1197... Val Loss: 1.9854\n","Epoch: 14/20... Step: 350... Loss: 1.9405... Val Loss: 1.7959\n","Epoch: 16/20... Step: 400... Loss: 1.8122... Val Loss: 1.6625\n","Epoch: 18/20... Step: 450... Loss: 1.6288... Val Loss: 1.4857\n","Epoch: 20/20... Step: 500... Loss: 1.4512... Val Loss: 1.2859\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Un2-EJ8kyZyy","colab_type":"text"},"source":["### Test of the network: generation of single voice \n","We will now test the trained network to predict potential melodies starting from a short sequence of notes. Here again, the functions `predict` and `sample` are highly inspired from the Tutorial 8, and slightly modified towards pianorolls data processing. \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nAAp3PAX4lMH","colab":{}},"source":["\"\"# Defining a method to generate the next character\n","def predict(net, note, h=None):\n","        ''' Given a note, predict the next note.\n","            Returns the predicted note and the hidden state.\n","        '''\n","        \n","        # tensor inputs\n","        x = np.array([[note]])\n","        x = midi_utils.one_hot_encode_batch(x, net.n_notes)\n","        inputs = torch.from_numpy(x)\n","        \n","        if(train_on_gpu):\n","            inputs = inputs.cuda()\n","        \n","        # detach hidden state from history\n","        h = tuple([each.data for each in h])\n","        # get the output of the model\n","        out, h = net(inputs, h)\n","        \n","\n","        # get the character probabilities\n","        p = F.softmax(out, dim=1).data\n","        if(train_on_gpu):\n","            p = p.cpu() # move to cpu\n","        \n","        note_range = np.arange(net.n_notes)\n","        # select the likely next note with some element of randomness\n","        p = p.numpy().squeeze()\n","        note = np.random.choice(note_range, p=p/p.sum())\n","        \n","        # return the encoded value of the predicted char and the hidden state\n","        return note, h"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UWOVgrS64lMI","colab":{}},"source":["# Declaring a method to generate new melody\n","def sample(net, size, prime=[10,10,12,12]):\n","        \n","    if(train_on_gpu):\n","        net.cuda()\n","    else:\n","        net.cpu()\n","    \n","    net.eval() # eval mode\n","    \n","    # First off, run through the prime notes\n","    notes = [no for no in prime]\n","    h = net.init_hidden(1)\n","    for no in prime:\n","        note, h = predict(net, no, h)\n","    notes.append(note)\n","    \n","    # Now pass in the previous note and get a new one\n","    for ii in range(size):\n","        note, h = predict(net, notes[-1], h)\n","        notes.append(note)\n","\n","    return np.array(notes)\n","\n","\n","\n","def sample_harmonization(net, seq, prime):\n","        \n","    if(train_on_gpu):\n","        net.cuda()\n","    else:\n","        net.cpu()\n","    \n","    net.eval() # eval mode\n","    \n","    size = len(seq)\n","    \n","    # First off, run through the prime notes\n","    notes = [no for no in prime]\n","    h = net.init_hidden(1)\n","    for no in prime:\n","        note, h = predict(net, no, h)\n","    notes.append(note)\n","    \n","    # Now pass in the previous character and get a new one\n","    for ii in range(5,size):\n","        note, h = predict(net, seq[ii], h)\n","        notes.append(note)\n","\n","    return np.array(notes)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"om0ch5hlz7oC","colab_type":"text"},"source":["The `NoteRNN` network outputs scaled pianorolls. We thus need to send back the obtained pitches to the associated voice range, using the function `unscale_pianoroll`. We then store the pianoroll to a track object, and to a multitrack object, which can directly be used to write a midi file. "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557736047963,"user_tz":-120,"elapsed":507,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"dDlgi2OM4lMJ","outputId":"50a82c65-5ec3-479a-c084-4608bbc80279","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["# Generating new melody\n","start = 72 - global_lower + 1 # starting with a C \n","notes = sample(net, 200, prime=[start,start,start+2,start+2])\n","print(\"Generated sample :\")\n","print(notes)\n","normal_pianoroll = midi_utils.unscale_pianoroll(notes, global_lower) # go back to the track range\n","print(\"Generated sample in the pitch range :\")\n","print(normal_pianoroll)\n","# create a one_hot_pianoroll\n","one_hot_pianoroll = midi_utils.one_hot_encode_pianoroll(normal_pianoroll, 128)*90 # 90 for the velocity\n","# store it a in a track object\n","new_track = Track(pianoroll=one_hot_pianoroll, name='new track')\n","# create a multitrack made of the generated track object\n","new_multitrack = Multitrack(tracks=[new_track], tempo = 90, beat_resolution=4)\n","#write to midi file \n","pypianoroll.write(new_multitrack, home_dir + \"/results/RNN_track\")\n","modified_midi_filename = home_dir + \"/results/RNN_track.mid\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Generated sample :\n","[16 16 18 18 18 18 18 18 18 18  0 20 20 20 20 16 16 16 16 16 16 16 20 20\n"," 20  0 20 20 21 21 23 23 23  0 23 23 20 23 18 18 18 18 20 20 20  0 20 20\n"," 20 20 18 18 16 16 15 15 13 13 15 15 15 15 13 13 13  0 13 13 13  0 13 13\n"," 13  0 13 13 13 13 11 11 11  0 11 11 11  0 11 11 11 11 16 16 16 16 18 18\n"," 18 18 20 20 20 20 18 18 18 18 18 18 16 16 15 15 15 15 13 13 13 13 16 16\n"," 15 15 13 13 13 13 15 15 15 15 16 16 16 16 15 15 15 15 13 13 13 13  0  0\n","  0  0 13 13 14  0 14 14 13 13  9  9  9  9  8  8  8  8 13 13 13 13 11 11\n"," 11 11 16 16 16 16 13 13 15 15 16 16 16  0 16 16 16 16 15 15 15 15 13 13\n","  0 13 11 11 11 16 16 16 16 15 15 15 15]\n","Generated sample in the pitch range :\n","[72 72 74 74 74 74 74 74 74 74  0 76 76 76 76 72 72 72 72 72 72 72 76 76\n"," 76  0 76 76 77 77 79 79 79  0 79 79 76 79 74 74 74 74 76 76 76  0 76 76\n"," 76 76 74 74 72 72 71 71 69 69 71 71 71 71 69 69 69  0 69 69 69  0 69 69\n"," 69  0 69 69 69 69 67 67 67  0 67 67 67  0 67 67 67 67 72 72 72 72 74 74\n"," 74 74 76 76 76 76 74 74 74 74 74 74 72 72 71 71 71 71 69 69 69 69 72 72\n"," 71 71 69 69 69 69 71 71 71 71 72 72 72 72 71 71 71 71 69 69 69 69  0  0\n","  0  0 69 69 70  0 70 70 69 69 65 65 65 65 64 64 64 64 69 69 69 69 67 67\n"," 67 67 72 72 72 72 69 69 71 71 72 72 72  0 72 72 72 72 71 71 71 71 69 69\n","  0 69 67 67 67 72 72 72 72 71 71 71 71]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a1zoH626TqKk","colab_type":"code","colab":{}},"source":["!apt install fluidsynth\n","!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n","!pip install midi2audio\n","from midi2audio import FluidSynth\n","from IPython.display import Audio\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7_AvsYET_TX","colab_type":"code","outputId":"6206eddd-1f29-4dd7-ccf7-d2f2ac5d2ac2","executionInfo":{"status":"ok","timestamp":1557736059023,"user_tz":-120,"elapsed":7806,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"17Q9VVEcvm_RFRKv4uriNqz1J7Bo_1P1O"}},"source":["FluidSynth(\"font.sf2\").midi_to_audio(modified_midi_filename, 'test.wav')\n","Audio(\"test.wav\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n-06icmc4lMK","colab":{}},"source":["\n","pygame.init()\n","pygame.mixer.music.load(modified_midi_filename)\n","pygame.mixer.music.play()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1557504269655,"user_tz":-120,"elapsed":511,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"MMWx1qQs4lML","outputId":"80d34808-4e3b-41d1-a467-6e0af08633bd","colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["pygame.mixer.music.stop()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-bb1c42b42b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vEo6s6GV-_I3"},"source":["## Train for harmonization"]},{"cell_type":"markdown","metadata":{"id":"qkoVhdWWEIsz","colab_type":"text"},"source":["We observed above that it is possible to generate a coherent melody using a slightly modified version of the original character-to-character RNN. Here, we will investigate whether such a network can perform more complex task, such as harmonizing a given voice. For instance, from the soprano sequence, we would like to generate the associated alto voice. "]},{"cell_type":"code","metadata":{"id":"NQSTEDZrV70O","colab_type":"code","colab":{}},"source":["beat_resolution = 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KK_JGdyb-_I4","colab":{}},"source":["\n","all_pianorolls_soprano = get_all_pianorolls(0, home_dir, beat_resolution=beat_resolution)\n","all_pianorolls_alto = get_all_pianorolls(1, home_dir, beat_resolution=beat_resolution)\n","all_pianorolls_tenor = get_all_pianorolls(2, home_dir, beat_resolution=beat_resolution)\n","all_pianorolls_bass = get_all_pianorolls(3, home_dir, beat_resolution=beat_resolution)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557750317882,"user_tz":-120,"elapsed":28431,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"A1XAhpRy-_I4","outputId":"5316e472-6a4a-4741-d95e-50ab3cd2a2d7","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["list_pianorolls = [all_pianorolls_soprano, all_pianorolls_alto, all_pianorolls_tenor, all_pianorolls_bass]\n","global_lower, global_upper, n_notes = get_extremum_pitches(list_pianorolls)\n","\n","\n","print('Global lower note : '+ str(global_lower))\n","print('Global upper note : '+ str(global_upper))\n","print('Number of notes : '+ str(n_notes))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Global lower note : 35\n","Global upper note : 83\n","Number of notes : 50\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2wBxcVc3VCOn","colab_type":"text"},"source":["We now rescale the pianorolls to values next to 0. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SvlOqRm3-_I7","colab":{}},"source":["# scale pianoroll to 0 \n","all_pianorolls_soprano = midi_utils.scale_pianoroll(all_pianorolls_soprano, global_lower)\n","all_pianorolls_alto = midi_utils.scale_pianoroll(all_pianorolls_alto, global_lower)\n","all_pianorolls_tenor = midi_utils.scale_pianoroll(all_pianorolls_tenor, global_lower)\n","all_pianorolls_bass = midi_utils.scale_pianoroll(all_pianorolls_bass, global_lower)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5JMisjMIm2A","colab_type":"text"},"source":["It is now time to train the network to perform harmonization. Setting the mode to `\"harmonization\"`, we will call the function `get_pianoroll_batches_harmonization` that generates one-hot vectors of both input and target melodies. "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557755548460,"user_tz":-120,"elapsed":66642,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"bAWv5b1A-_I8","outputId":"bdbbd85e-3c34-462a-93e0-eb05758d1db7","colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["# Define and print the net\n","n_hidden=512\n","n_layers=2\n","\n","net_harmonization_alto = NoteRNN(n_notes, n_hidden, n_layers)\n","net_harmonization_tenor = NoteRNN(n_notes, n_hidden, n_layers)\n","net_harmonization_bass = NoteRNN(n_notes, n_hidden, n_layers)\n","\n","\n","\n","# Declaring the hyperparameters\n","batch_size = 64\n","seq_length = 50\n","n_epochs = 100 # start smaller if you are just testing initial behavior\n","\n","# train the model\n","train(net_harmonization_alto, data=all_pianorolls_soprano, data2=all_pianorolls_alto, mode=\"harmonization\", epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.005, print_every=50)"],"execution_count":253,"outputs":[{"output_type":"stream","text":["Epoch: 5/100... Step: 50... Loss: 2.6837... Val Loss: 2.6952\n","Epoch: 9/100... Step: 100... Loss: 2.1628... Val Loss: 2.1865\n","Epoch: 13/100... Step: 150... Loss: 1.9556... Val Loss: 2.0641\n","Epoch: 17/100... Step: 200... Loss: 1.7638... Val Loss: 1.9552\n","Epoch: 21/100... Step: 250... Loss: 1.7696... Val Loss: 1.9305\n","Epoch: 25/100... Step: 300... Loss: 1.6271... Val Loss: 1.9085\n","Epoch: 30/100... Step: 350... Loss: 1.5377... Val Loss: 1.8743\n","Epoch: 34/100... Step: 400... Loss: 1.5111... Val Loss: 1.9149\n","Epoch: 38/100... Step: 450... Loss: 1.4121... Val Loss: 1.9774\n","Epoch: 42/100... Step: 500... Loss: 1.2328... Val Loss: 2.0196\n","Epoch: 46/100... Step: 550... Loss: 1.1948... Val Loss: 2.0242\n","Epoch: 50/100... Step: 600... Loss: 1.0025... Val Loss: 2.1039\n","Epoch: 55/100... Step: 650... Loss: 0.8604... Val Loss: 2.2634\n","Epoch: 59/100... Step: 700... Loss: 0.8123... Val Loss: 2.3946\n","Epoch: 63/100... Step: 750... Loss: 0.7413... Val Loss: 2.5258\n","Epoch: 67/100... Step: 800... Loss: 0.6590... Val Loss: 2.7472\n","Epoch: 71/100... Step: 850... Loss: 0.6389... Val Loss: 2.7598\n","Epoch: 75/100... Step: 900... Loss: 0.4240... Val Loss: 2.9060\n","Epoch: 80/100... Step: 950... Loss: 0.3014... Val Loss: 3.0812\n","Epoch: 84/100... Step: 1000... Loss: 0.2995... Val Loss: 3.3036\n","Epoch: 88/100... Step: 1050... Loss: 0.2608... Val Loss: 3.4639\n","Epoch: 92/100... Step: 1100... Loss: 0.2709... Val Loss: 3.4854\n","Epoch: 96/100... Step: 1150... Loss: 0.1760... Val Loss: 3.6120\n","Epoch: 100/100... Step: 1200... Loss: 0.1857... Val Loss: 3.7420\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZkYgqAfIeBJb","colab_type":"code","outputId":"b096aae6-9fcd-4afa-8b9b-7a298f48f17c","executionInfo":{"status":"ok","timestamp":1557755614518,"user_tz":-120,"elapsed":131586,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["train(net_harmonization_tenor, data=all_pianorolls_soprano, data2=all_pianorolls_tenor, mode=\"harmonization\", epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.005, print_every=50)"],"execution_count":254,"outputs":[{"output_type":"stream","text":["Epoch: 5/100... Step: 50... Loss: 2.6854... Val Loss: 2.9172\n","Epoch: 9/100... Step: 100... Loss: 2.5042... Val Loss: 2.4858\n","Epoch: 13/100... Step: 150... Loss: 2.2193... Val Loss: 2.2892\n","Epoch: 17/100... Step: 200... Loss: 1.9316... Val Loss: 2.0811\n","Epoch: 21/100... Step: 250... Loss: 1.8708... Val Loss: 2.0714\n","Epoch: 25/100... Step: 300... Loss: 1.7279... Val Loss: 2.0192\n","Epoch: 30/100... Step: 350... Loss: 1.6773... Val Loss: 2.0358\n","Epoch: 34/100... Step: 400... Loss: 1.6837... Val Loss: 2.0381\n","Epoch: 38/100... Step: 450... Loss: 1.5756... Val Loss: 2.0743\n","Epoch: 42/100... Step: 500... Loss: 1.4114... Val Loss: 2.0881\n","Epoch: 46/100... Step: 550... Loss: 1.4110... Val Loss: 2.1512\n","Epoch: 50/100... Step: 600... Loss: 1.1396... Val Loss: 2.2130\n","Epoch: 55/100... Step: 650... Loss: 1.0974... Val Loss: 2.3089\n","Epoch: 59/100... Step: 700... Loss: 1.0607... Val Loss: 2.3965\n","Epoch: 63/100... Step: 750... Loss: 0.7752... Val Loss: 2.5673\n","Epoch: 67/100... Step: 800... Loss: 0.7034... Val Loss: 2.7341\n","Epoch: 71/100... Step: 850... Loss: 0.7224... Val Loss: 2.7783\n","Epoch: 75/100... Step: 900... Loss: 0.4989... Val Loss: 2.9526\n","Epoch: 80/100... Step: 950... Loss: 0.3643... Val Loss: 3.2024\n","Epoch: 84/100... Step: 1000... Loss: 0.3896... Val Loss: 3.3094\n","Epoch: 88/100... Step: 1050... Loss: 0.2658... Val Loss: 3.6006\n","Epoch: 92/100... Step: 1100... Loss: 0.2292... Val Loss: 3.7438\n","Epoch: 96/100... Step: 1150... Loss: 0.1756... Val Loss: 3.8225\n","Epoch: 100/100... Step: 1200... Loss: 0.1480... Val Loss: 4.0214\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SoQKIHoPeJDU","colab_type":"code","outputId":"ffb364e1-dca6-471b-a54e-8aa49fa08e29","executionInfo":{"status":"ok","timestamp":1557755680363,"user_tz":-120,"elapsed":196940,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["train(net_harmonization_bass, data=all_pianorolls_soprano, data2=all_pianorolls_bass, mode=\"harmonization\", epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.005, print_every=50)"],"execution_count":255,"outputs":[{"output_type":"stream","text":["Epoch: 5/100... Step: 50... Loss: 2.8779... Val Loss: 2.7923\n","Epoch: 9/100... Step: 100... Loss: 2.6281... Val Loss: 2.6543\n","Epoch: 13/100... Step: 150... Loss: 2.3573... Val Loss: 2.3237\n","Epoch: 17/100... Step: 200... Loss: 2.0670... Val Loss: 2.1591\n","Epoch: 21/100... Step: 250... Loss: 2.0083... Val Loss: 2.0996\n","Epoch: 25/100... Step: 300... Loss: 1.7172... Val Loss: 2.1159\n","Epoch: 30/100... Step: 350... Loss: 1.5050... Val Loss: 2.1937\n","Epoch: 34/100... Step: 400... Loss: 1.2510... Val Loss: 2.3346\n","Epoch: 38/100... Step: 450... Loss: 1.0879... Val Loss: 2.4346\n","Epoch: 42/100... Step: 500... Loss: 0.9572... Val Loss: 2.6733\n","Epoch: 46/100... Step: 550... Loss: 0.6880... Val Loss: 2.8188\n","Epoch: 50/100... Step: 600... Loss: 0.5870... Val Loss: 3.0196\n","Epoch: 55/100... Step: 650... Loss: 0.3647... Val Loss: 3.2446\n","Epoch: 59/100... Step: 700... Loss: 0.3840... Val Loss: 3.4572\n","Epoch: 63/100... Step: 750... Loss: 0.3125... Val Loss: 3.6780\n","Epoch: 67/100... Step: 800... Loss: 0.2377... Val Loss: 3.7767\n","Epoch: 71/100... Step: 850... Loss: 0.2372... Val Loss: 3.9734\n","Epoch: 75/100... Step: 900... Loss: 0.1413... Val Loss: 4.0876\n","Epoch: 80/100... Step: 950... Loss: 0.0806... Val Loss: 4.1867\n","Epoch: 84/100... Step: 1000... Loss: 0.1555... Val Loss: 4.3553\n","Epoch: 88/100... Step: 1050... Loss: 0.0648... Val Loss: 4.3918\n","Epoch: 92/100... Step: 1100... Loss: 0.1130... Val Loss: 4.3983\n","Epoch: 96/100... Step: 1150... Loss: 0.2804... Val Loss: 4.2391\n","Epoch: 100/100... Step: 1200... Loss: 0.4367... Val Loss: 3.7408\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aZW3uAKC4lMM","colab":{}},"source":[" # Generating harmonization\n","\n","os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir\n","# get one voice from the dataset \n","#midi_filename = 'bwv368.mid'\n","midi_filename = 'bwv155.5.mid'\n","#midi_filename = 'pkgsc_azalea.mid'\n","soprano_track = get_track_transposed(midi_filename, 0, beat_resolution=beat_resolution, transpose=True)\n","alto_track_real = get_track_transposed(midi_filename, 1, beat_resolution=beat_resolution, transpose=True)\n","tenor_track_real = get_track_transposed(midi_filename, 2, beat_resolution=beat_resolution, transpose=True)\n","bass_track_real = get_track_transposed(midi_filename, 3, beat_resolution=beat_resolution, transpose=True)\n","\n","soprano_pianoroll = midi_utils.scale_pianoroll(midi_utils.flatten_one_hot_pianoroll(soprano_track.pianoroll), global_lower)\n","alto_pianoroll_real = midi_utils.scale_pianoroll(midi_utils.flatten_one_hot_pianoroll(alto_track_real.pianoroll), global_lower)\n","tenor_pianoroll_real = midi_utils.scale_pianoroll(midi_utils.flatten_one_hot_pianoroll(tenor_track_real.pianoroll), global_lower)\n","bass_pianoroll_real = midi_utils.scale_pianoroll(midi_utils.flatten_one_hot_pianoroll(bass_track_real.pianoroll), global_lower)\n","\n","\n","# now we can predict the second voice \n","alto_pianoroll = sample_harmonization(net_harmonization_alto, soprano_pianoroll, prime = alto_pianoroll_real[:4])\n","\n","tenor_pianoroll = sample_harmonization(net_harmonization_tenor, soprano_pianoroll, prime = tenor_pianoroll_real[:4])\n","bass_pianoroll = sample_harmonization(net_harmonization_bass, soprano_pianoroll, prime = bass_pianoroll_real[:4])\n","\n","# go back to the pitch range \n","alto_pianoroll = midi_utils.unscale_pianoroll(alto_pianoroll, global_lower)\n","tenor_pianoroll = midi_utils.unscale_pianoroll(tenor_pianoroll, global_lower)\n","bass_pianoroll = midi_utils.unscale_pianoroll(bass_pianoroll, global_lower)\n","\n","# convert to one-hot representation for track object\n","alto_onehot = midi_utils.one_hot_encode_pianoroll(alto_pianoroll, 128)*90\n","tenor_onehot = midi_utils.one_hot_encode_pianoroll(tenor_pianoroll, 128)*90\n","bass_onehot = midi_utils.one_hot_encode_pianoroll(bass_pianoroll, 128)*90\n","\n","alto_track = Track(pianoroll=alto_onehot, name='alto gernerated track')\n","tenor_track = Track(pianoroll=tenor_onehot, name='tenor gernerated track')\n","bass_track = Track(pianoroll=bass_onehot, name='bass gernerated track')\n","# create a multitrack made of the initial soprano track and the generated alto\n","new_multitrack = Multitrack(tracks=[soprano_track, alto_track, tenor_track, bass_track], tempo = 90, beat_resolution=beat_resolution)\n","\n","multitrack_real = Multitrack(tracks=[soprano_track, alto_track_real, tenor_track_real, bass_track_real], tempo = 90, beat_resolution=beat_resolution)\n","#write to midi file \n","pypianoroll.write(new_multitrack, home_dir + \"/results/RNN_harmonization_track\")\n","pypianoroll.write(multitrack_real, home_dir + \"/results/RNN_harmonization_track_real\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"78YbppxNUxt-","colab_type":"code","outputId":"23ab0bf2-dcdb-477e-9d1e-a99200ad25f3","executionInfo":{"status":"ok","timestamp":1557755842254,"user_tz":-120,"elapsed":9583,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1OeU-pRYyjtywIyK-aeRIVgI6klQjpSLI"}},"source":["modified_midi_filename = home_dir + \"/results/RNN_harmonization_track.mid\"\n","FluidSynth(\"font.sf2\").midi_to_audio(modified_midi_filename, 'test_fake.wav')\n","Audio(\"test_fake.wav\")"],"execution_count":263,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"zAfF0mMcbHDr","colab_type":"code","outputId":"556f4fea-d5cf-4627-b162-4c68d324d9c1","executionInfo":{"status":"ok","timestamp":1557755819568,"user_tz":-120,"elapsed":12527,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1Dg-ggnXAcJypf4RWoa0K1A3yyD_6JUYt"}},"source":["modified_midi_filename_real = home_dir + \"/results/RNN_harmonization_track_real.mid\"\n","FluidSynth(\"font.sf2\").midi_to_audio(modified_midi_filename_real, 'test_real.wav')\n","Audio(\"test_real.wav\")"],"execution_count":262,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1557736711266,"user_tz":-120,"elapsed":64606,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"D9c_NQ5q-_I-","outputId":"a75b4d5a-cfe0-4aa2-b29d-f55b1b66927d","colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["modified_midi_filename = home_dir + \"/results/RNN_harmonization_track.mid\"\n","pygame.init()\n","pygame.mixer.music.load(modified_midi_filename)\n","pygame.mixer.music.play()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-b59c140a6544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodified_midi_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/results/RNN_harmonization_track.mid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_midi_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MpStKEvO-_I-","outputId":"354ac2d5-19ad-4310-8e4a-a920b4a68dcc","executionInfo":{"status":"error","timestamp":1557504611177,"user_tz":-120,"elapsed":663,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["pygame.mixer.music.stop()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-bb1c42b42b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"562Tt2rR-_I_","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}