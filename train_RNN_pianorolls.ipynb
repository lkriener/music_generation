{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_RNN_pianorolls.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495831558,"user_tz":-120,"elapsed":3607,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"kfpjADwL4oUx","outputId":"e5d6c3a4-fe8e-484a-9339-d32e4f015b45","colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["# Uncomment the line below and run this cell to get your data from github into colab (only runnable in colab, not ordinary jupyter notebook):\n","! git clone https://github.com/lkriener/music_generation.git && mv music_generation/* . && rm music_generation -r"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'music_generation'...\n","remote: Enumerating objects: 495, done.\u001b[K\n","remote: Counting objects: 100% (495/495), done.\u001b[K\n","remote: Compressing objects: 100% (454/454), done.\u001b[K\n","remote: Total 495 (delta 64), reused 462 (delta 34), pack-reused 0\u001b[K\n","Receiving objects: 100% (495/495), 417.31 KiB | 8.35 MiB/s, done.\n","Resolving deltas: 100% (64/64), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495839807,"user_tz":-120,"elapsed":11846,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"sLhyMMRj4tNz","outputId":"1b95a3e8-a266-4e15-e1b7-fca360cf8e44","colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["# Uncomment line to install requirements\n","! pip install -r colab_requirements.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pygame==1.9.6 (from -r colab_requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n","\u001b[K     |████████████████████████████████| 11.4MB 3.4MB/s \n","\u001b[?25hCollecting py_midicsv==1.9.0 (from -r colab_requirements.txt (line 3))\n","  Downloading https://files.pythonhosted.org/packages/1f/eb/3133f65bd34dafcbae37508d290ebf540832430cbe2aef23629cc6a6197f/py_midicsv-1.9.0-py3-none-any.whl\n","Collecting pypianoroll==0.5.0 (from -r colab_requirements.txt (line 4))\n","  Downloading https://files.pythonhosted.org/packages/aa/33/fa38c07909e425add987146cb0f8d5ad80262f6a72cc820bf7e5f690d527/pypianoroll-0.5.0.tar.gz\n","Requirement already satisfied: six<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.12.0)\n","Requirement already satisfied: numpy<2.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.16.3)\n","Requirement already satisfied: scipy<2.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.2.1)\n","Requirement already satisfied: pretty_midi<1.0,>=0.2.8 in /usr/local/lib/python3.6/dist-packages (from pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (0.2.8)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/dist-packages (from pretty_midi<1.0,>=0.2.8->pypianoroll==0.5.0->-r colab_requirements.txt (line 4)) (1.2.6)\n","Building wheels for collected packages: pypianoroll\n","  Building wheel for pypianoroll (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/ed/f6/fb/5d070524ecf7ba9ed201247a293c01945cfd7f840f8ef338c0\n","Successfully built pypianoroll\n","Installing collected packages: pygame, py-midicsv, pypianoroll\n","Successfully installed py-midicsv-1.9.0 pygame-1.9.6 pypianoroll-0.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DaVKNWw4lLr","colab":{}},"source":["import src.midi_utils as midi_utils\n","import pygame\n","from pypianoroll import Multitrack, Track\n","import pypianoroll\n","import os\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HygKqpcn-_Ih","colab_type":"text"},"source":["## Test of pypianoroll library\n","We will first use the pypianoroll library - https://salu133445.github.io/pypianoroll/ - to convert a midi file into a multitrack object, get the soprano track, transpose it to C major, create a new multitrack object out of it, and finally write it to a new midi file. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IugBxMoP4lLy","colab":{}},"source":["try:\n","    home_dir\n","except NameError:\n","    home_dir = os.getcwd()\n","\n","os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BrAiT6ot4lL2","colab":{}},"source":["from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n","from torch.utils.data import DataLoader\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","feature_scaler = StandardScaler()\n","label_scaler = StandardScaler()\n","\n","# iterate over all midi files of folder\n","import glob\n","import os\n","import numpy as np\n","\n","try:\n","    home_dir\n","except NameError:\n","    home_dir = os.getcwd()\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zVNrDFfI4lL4","colab":{}},"source":["# determine boundaries in all tracks\n","lower_notes = []\n","upper_notes = []\n","list_pianorolls = []\n","os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir\n","for midi_file in glob.glob(\"*.mid\"):\n","    ## load midi file\n","    csv_text = midi_utils.load_to_csv(midi_file)\n","    # get semitones to C major \n","    semitones,_ = midi_utils.get_semitones_to_C(csv_text)\n","    # convert to multitrack object\n","    multitrack = pypianoroll.parse(midi_file, beat_resolution=2)\n","    # get the soprano track object and transpose it to C major \n","    track = pypianoroll.transpose(multitrack.tracks[0], -semitones)\n","    \n","    # get pitch range \n","    pitch_range = track.get_active_pitch_range()\n","    lower_notes.append(pitch_range[0])\n","    upper_notes.append(pitch_range[1])\n","    \n","    # get the flattened representation of pianoroll\n","    pianoroll_flattened = midi_utils.flatten_one_hot_pianoroll(track.pianoroll)\n","    # add it to the global list of all tracks\n","    list_pianorolls.append(pianoroll_flattened)\n","\n","# convert into an array \n","all_pianorolls = np.concatenate(list_pianorolls)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495876940,"user_tz":-120,"elapsed":6702,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"8EnWFvKA4lL7","outputId":"3b78123e-3b9f-4240-d83a-88f4b466929b","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# get lower and upper bounds \n","global_lower = min(lower_notes)\n","global_upper = max(upper_notes)\n","global_diff = global_upper - global_lower\n","n_notes = global_diff + 2 # we include the silence \n","print('Global lower note : '+ str(global_lower))\n","print('Global upper note : '+ str(global_upper))\n","print('Number of notes : '+ str(n_notes))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Global lower note : 57\n","Global upper note : 83\n","Number of notes : 28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495876941,"user_tz":-120,"elapsed":6144,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"P3Tts_gs4lL9","outputId":"8e57f8aa-020c-45a4-bc1a-91ddb513fcd3","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print(all_pianorolls[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 0  0 69  0 69  0 69 69 68 66 64 64 69 69 71 71 72  0 72 72 74 74 72 72\n"," 71  0 71 71 72 72 74 74 76 74 72 72 77  0 77 77 76 74 76 76 74 74 74 74\n"," 72  0 72 72 71 71 69 69 67 67 64 65 67  0 67 67 69 69 67 67 65 65 65 65\n"," 64 64 76 76 74 74 72 72 71 71 71 71 69 69 69 69 69 69  0  0 68 68 70 70\n"," 70 70 68 68]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495882720,"user_tz":-120,"elapsed":434,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"ayfyARad4lL_","outputId":"f1dc3ebf-4641-40c3-f857-86b129c38240","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# scale pianoroll to 0 \n","all_pianorolls_scaled = midi_utils.scale_pianoroll(all_pianorolls, global_lower)\n","print(all_pianorolls_scaled[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 0  0 13  0 13  0 13 13 12 10  8  8 13 13 15 15 16  0 16 16 18 18 16 16\n"," 15  0 15 15 16 16 18 18 20 18 16 16 21  0 21 21 20 18 20 20 18 18 18 18\n"," 16  0 16 16 15 15 13 13 11 11  8  9 11  0 11 11 13 13 11 11  9  9  9  9\n","  8  8 20 20 18 18 16 16 15 15 15 15 13 13 13 13 13 13  0  0 12 12 14 14\n"," 14 14 12 12]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mNOwMHKR4lMA"},"source":["## Define a recurrent-network model "]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557495883700,"user_tz":-120,"elapsed":423,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"b37NFyC-4lMB","outputId":"8575e2a5-9779-40c2-959a-ebec33976d51","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Check if GPU is available\n","train_on_gpu = torch.cuda.is_available()\n","if(train_on_gpu):\n","    print('Training on GPU!')\n","else: \n","    print('No GPU available, training on CPU; consider making n_epochs very small.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on GPU!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mrVryIjJ4lMC"},"source":["## Define a LSTM network as for note-to-note melody generation\n","We now build a network to implement note-to-note melody generation using LSTMs units as well as drop-out of the output. This network is highly inspired from the Tutorial 08 of the class, by replacing characters by notes. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IPccoLL84lMD","colab":{}},"source":["# Declaring the model\n","class NoteRNN(nn.Module):\n","    \n","    def __init__(self, n_notes, n_hidden=256, n_layers=2,\n","                               drop_prob=0.5, lr=0.001):\n","        super().__init__()\n","        self.drop_prob = drop_prob\n","        self.n_layers = n_layers\n","        self.n_hidden = n_hidden\n","        self.lr = lr\n","        \n","        self.n_notes = n_notes \n","        #define the LSTM\n","        self.lstm = nn.LSTM(self.n_notes, n_hidden, n_layers, \n","                            dropout=drop_prob, batch_first=True)\n","        \n","        #define a dropout layer\n","        self.dropout = nn.Dropout(drop_prob)\n","        \n","        #define the final, fully-connected output layer\n","        self.fc = nn.Linear(n_hidden, self.n_notes)\n","      \n","    \n","    def forward(self, x, hidden):\n","        ''' Forward pass through the network. \n","            These inputs are x, and the hidden/cell state `hidden`. '''\n","                \n","        #get the outputs and the new hidden state from the lstm\n","        r_output, hidden = self.lstm(x, hidden)\n","        \n","        #pass through a dropout layer\n","        out = self.dropout(r_output)\n","        \n","        # Stack up LSTM outputs using view\n","        out = out.contiguous().view(-1, self.n_hidden)\n","        \n","        #put x through the fully-connected layer\n","        out = self.fc(out)\n","        \n","        # return the final output and the hidden state\n","        return out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n","                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n","        \n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GxUeYhz24lME"},"source":["## Training Code\n","\n","Time for training! We declare a function, where we define an optimizer (Adam) and loss (cross entropy). We then create the training and validation data and initialize the hidden state of the RNN. \n","We loop over the training set, each time encoding the data into one-hot vectors, performing forward and backpropagation, and updating the network parameters.\n","\n","Every once a while, we generate some loss statistics (training loss and validation loss) to let us know if the model is training correctly."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ySgtX9jT4lME","colab":{}},"source":["# Declaring the train method\n","def train(net, data, data2=None, mode=\"melody_generation\", epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n","    ''' Training a network \n","    \n","        Arguments\n","        ---------\n","        \n","        net: NoteRNN network\n","        data: text data to train the network\n","        epochs: Number of epochs to train\n","        batch_size: Number of mini-sequences per mini-batch, aka batch size\n","        seq_length: Number of character steps per mini-batch\n","        lr: learning rate\n","        clip: gradient clipping\n","        val_frac: Fraction of data to hold out for validation\n","        print_every: Number of steps for printing training and validation loss\n","    \n","    '''\n","    net.train()\n","    \n","    opt = torch.optim.Adam(net.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # create training and validation data\n","    val_idx = int(len(data)*(1-val_frac))\n","    data, val_data = data[:val_idx], data[val_idx:]\n","    if mode == \"harmonization\":\n","        data2, val_data2 = data2[:val_idx], data2[val_idx:]\n","    \n","    if(train_on_gpu):\n","        net.cuda()\n","        \n","    counter = 0\n","    n_notes = net.n_notes \n","    for e in range(epochs):\n","        # initialize hidden state\n","        h = net.init_hidden(batch_size)\n","        \n","        if mode == \"melody_generation\":\n","            batch_generator = midi_utils.get_pianoroll_batches(data, batch_size, seq_length)\n","        elif mode == \"harmonization\":\n","            batch_generator = midi_utils.get_pianoroll_batches_harmonization(data, data2, batch_size, seq_length)\n","        for x, y in batch_generator:\n","            counter += 1\n","            \n","            # One-hot encode our data and make them Torch tensors\n","            x = midi_utils.one_hot_encode_batch(x, n_notes)\n","            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n","            if(train_on_gpu):\n","                inputs, targets = inputs.cuda(), targets.cuda()\n","\n","            # Creating new variables for the hidden state, otherwise\n","            # we'd backprop through the entire training history\n","            h = tuple([each.data for each in h])\n","\n","            # zero accumulated gradients\n","            net.zero_grad()\n","            \n","            # get the output from the model\n","            output, h = net(inputs, h)\n","            # calculate the loss and perform backprop\n","            loss = criterion(output, targets.view(batch_size*seq_length).long())\n","            loss.backward()\n","            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","            nn.utils.clip_grad_norm_(net.parameters(), clip)\n","            opt.step()\n","            \n","            # loss stats\n","            if counter % print_every == 0:\n","                # Get validation loss\n","                val_h = net.init_hidden(batch_size)\n","                val_losses = []\n","                net.eval()\n","                \n","                if mode == \"melody_generation\":\n","                    batch_generator_val = midi_utils.get_pianoroll_batches(val_data, batch_size, seq_length)\n","                elif mode == \"harmonization\":\n","                    batch_generator_val = midi_utils.get_pianoroll_batches_harmonization(val_data, val_data2, batch_size, seq_length)\n","                for x, y in batch_generator_val:\n","                    # One-hot encode our data and make them Torch tensors\n","                    x = midi_utils.one_hot_encode_batch(x, n_notes)\n","                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n","                    \n","                    # Creating new variables for the hidden state, otherwise\n","                    # we'd backprop through the entire training history\n","                    val_h = tuple([each.data for each in val_h])\n","                    \n","                    inputs, targets = x, y\n","                    if(train_on_gpu):\n","                        inputs, targets = inputs.cuda(), targets.cuda()\n","\n","                    output, val_h = net(inputs, val_h)\n","                    val_loss = criterion(output, targets.contiguous().view(batch_size*seq_length).long())\n","                \n","                    val_losses.append(val_loss.item())\n","                \n","                net.train() # reset to train mode after iterationg through validation data\n","                \n","                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                      \"Step: {}...\".format(counter),\n","                      \"Loss: {:.4f}...\".format(loss.item()),\n","                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_Gr3LZSO4lMF","colab":{}},"source":["# Define and print the net\n","n_hidden=256\n","n_layers=2\n","\n","net = NoteRNN(n_notes, n_hidden, n_layers)\n","print(net)\n","\n","# Declaring the hyperparameters\n","batch_size = 16\n","seq_length = 100\n","n_epochs = 20 # start smaller if you are just testing initial behavior\n","\n","# train the model\n","train(net, all_pianorolls_scaled, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nAAp3PAX4lMH","colab":{}},"source":["\"\"# Defining a method to generate the next character\n","def predict(net, note, h=None):\n","        ''' Given a note, predict the next note.\n","            Returns the predicted note and the hidden state.\n","        '''\n","        \n","        # tensor inputs\n","        x = np.array([[note]])\n","        x = midi_utils.one_hot_encode_batch(x, net.n_notes)\n","        inputs = torch.from_numpy(x)\n","        \n","        if(train_on_gpu):\n","            inputs = inputs.cuda()\n","        \n","        # detach hidden state from history\n","        h = tuple([each.data for each in h])\n","        # get the output of the model\n","        out, h = net(inputs, h)\n","        \n","\n","        # get the character probabilities\n","        p = F.softmax(out, dim=1).data\n","        if(train_on_gpu):\n","            p = p.cpu() # move to cpu\n","        \n","        note_range = np.arange(net.n_notes)\n","        # select the likely next note with some element of randomness\n","        p = p.numpy().squeeze()\n","        note = np.random.choice(note_range, p=p/p.sum())\n","        \n","        # return the encoded value of the predicted char and the hidden state\n","        return note, h"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UWOVgrS64lMI","colab":{}},"source":["# Declaring a method to generate new melody\n","def sample(net, size, prime=[10,10,12,12]):\n","        \n","    if(train_on_gpu):\n","        net.cuda()\n","    else:\n","        net.cpu()\n","    \n","    net.eval() # eval mode\n","    \n","    # First off, run through the prime characters\n","    notes = [no for no in prime]\n","    h = net.init_hidden(1)\n","    for no in prime:\n","        note, h = predict(net, no, h)\n","    notes.append(note)\n","    \n","    # Now pass in the previous character and get a new one\n","    for ii in range(size):\n","        note, h = predict(net, notes[-1], h)\n","        notes.append(note)\n","\n","    return np.array(notes)\n","\n","\n","# Declaring a method to generate new melody\n","def sample_harmonization(net, seq):\n","        \n","    if(train_on_gpu):\n","        net.cuda()\n","    else:\n","        net.cpu()\n","    \n","    net.eval() # eval mode\n","    \n","    size = len(seq)\n","    notes = []\n","    h = net.init_hidden(1)\n","    # Now pass in the previous character and get a new one\n","    for ii in range(size):\n","        note, h = predict(net, seq[ii], h)\n","        notes.append(note)\n","\n","    return np.array(notes)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557497774160,"user_tz":-120,"elapsed":423,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"dDlgi2OM4lMJ","outputId":"91773d86-a738-426b-8bf1-b94e9ee6c0a3","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Generating new melody\n","notes = sample(net, 100, prime=[1,1,1,1])\n","print(\"Generated sample :\")\n","print(notes)\n","normal_pianoroll = midi_utils.unscale_pianoroll(notes, global_lower) # go back to the track range\n","print(\"Generated sample in the pitch range :\")\n","print(normal_pianoroll)\n","# create a one_hot_pianoroll\n","one_hot_pianoroll = midi_utils.one_hot_encode_pianoroll(normal_pianoroll, 128)*90 # 90 for the velocity\n","# store it a in a track object\n","new_track = Track(pianoroll=one_hot_pianoroll, name='new track')\n","# create a multitrack made of the generated track object\n","new_multitrack = Multitrack(tracks=[new_track], tempo = 90, beat_resolution=2)\n","#write to midi file \n","pypianoroll.write(new_multitrack, home_dir + \"/results/RNN_track\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Generated sample :\n","[ 1  1  1  1 41 39 37 37  0 36 34 34 34 34  0 36 36 36 36 34 34 36 36 36\n","  0 39  0 39 39 39 37 39 41 41 41 41 41 39 39  0 39 34 34 34 36 37 37 38\n"," 37 36 36 34 41 39  0 39 36 36 36 36 34 34 36 36 36 36  0 41 41 40 41 39\n"," 37 37 37 37 36 36 34 34 34 36 32 34 34  0 36 36 36 36  0 34 36  0 36 36\n"," 34 34 34 32 32 31 31  0 29]\n","Generated sample in the pitch range :\n","[35 35 35 35 75 73 71 71  0 70 68 68 68 68  0 70 70 70 70 68 68 70 70 70\n","  0 73  0 73 73 73 71 73 75 75 75 75 75 73 73  0 73 68 68 68 70 71 71 72\n"," 71 70 70 68 75 73  0 73 70 70 70 70 68 68 70 70 70 70  0 75 75 74 75 73\n"," 71 71 71 71 70 70 68 68 68 70 66 68 68  0 70 70 70 70  0 68 70  0 70 70\n"," 68 68 68 66 66 65 65  0 63]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1557497775281,"user_tz":-120,"elapsed":405,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"id":"n-06icmc4lMK","outputId":"c9fccc0b-ba92-46a7-9b7e-4af2073cc75a","colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["modified_midi_filename = home_dir + \"/results/RNN_track.mid\"\n","pygame.init()\n","pygame.mixer.music.load(modified_midi_filename)\n","pygame.mixer.music.play()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-d0f533a7e311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodified_midi_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/results/RNN_track.mid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_midi_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MMWx1qQs4lML","outputId":"ef609cf3-b543-4d71-f0f7-2bcd6603467a","executionInfo":{"status":"error","timestamp":1557497775501,"user_tz":-120,"elapsed":267,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["pygame.mixer.music.stop()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-bb1c42b42b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"markdown","metadata":{"id":"vEo6s6GV-_I3","colab_type":"text"},"source":["## Train for harmonization"]},{"cell_type":"code","metadata":{"id":"KK_JGdyb-_I4","colab_type":"code","colab":{}},"source":["# determine boundaries in all tracks\n","lower_notes = []\n","upper_notes = []\n","list_pianorolls = []\n","list_pianorolls2 = []\n","os.chdir(home_dir + \"/data/raw/bach\")  # go to a folder relative to home dir\n","for midi_file in glob.glob(\"*.mid\"):\n","    ## load midi file\n","    csv_text = midi_utils.load_to_csv(midi_file)\n","    # get semitones to C major \n","    semitones,_ = midi_utils.get_semitones_to_C(csv_text)\n","    # convert to multitrack object\n","    multitrack = pypianoroll.parse(midi_file, beat_resolution=2)\n","    # get the soprano track object and transpose it to C major \n","    track = pypianoroll.transpose(multitrack.tracks[0], -semitones)\n","    track2 = pypianoroll.transpose(multitrack.tracks[3], -semitones)\n","    # get pitch range \n","    pitch_range = track.get_active_pitch_range()\n","    lower_notes.append(pitch_range[0])\n","    upper_notes.append(pitch_range[1])\n","    pitch_range2 = track2.get_active_pitch_range()\n","    lower_notes.append(pitch_range2[0])\n","    upper_notes.append(pitch_range2[1])\n","    \n","    \n","    \n","    # get the flattened representation of pianoroll\n","    pianoroll_flattened = midi_utils.flatten_one_hot_pianoroll(track.pianoroll)\n","    pianoroll_flattened2 = midi_utils.flatten_one_hot_pianoroll(track2.pianoroll)\n","    # add it to the global list of all tracks\n","    list_pianorolls.append(pianoroll_flattened)\n","    list_pianorolls2.append(pianoroll_flattened2)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1XAhpRy-_I4","colab_type":"code","outputId":"9f541a29-39c3-4399-a146-b41ff0f4fde8","executionInfo":{"status":"ok","timestamp":1557498852996,"user_tz":-120,"elapsed":3750,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# convert into an array \n","all_pianorolls = np.concatenate(list_pianorolls)\n","all_pianorolls2 = np.concatenate(list_pianorolls2)\n","# get lower and upper bounds \n","global_lower = min(lower_notes)\n","global_upper = max(upper_notes)\n","global_diff = global_upper - global_lower\n","n_notes = global_diff + 2 # we include the silence \n","print('Global lower note : '+ str(global_lower))\n","print('Global upper note : '+ str(global_upper))\n","print('Number of notes : '+ str(n_notes))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Global lower note : 35\n","Global upper note : 83\n","Number of notes : 50\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qwg4dWba-_I5","colab_type":"code","outputId":"f06499f4-e513-4483-b453-a8cb922fa155","executionInfo":{"status":"ok","timestamp":1557498852997,"user_tz":-120,"elapsed":834,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["print(\"Voice to train on :\")\n","print(all_pianorolls[0:100])\n","print(\"Voice to target :\")\n","print(all_pianorolls2[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Voice to train on :\n","[ 0  0 69  0 69  0 69 69 68 66 64 64 69 69 71 71 72  0 72 72 74 74 72 72\n"," 71  0 71 71 72 72 74 74 76 74 72 72 77  0 77 77 76 74 76 76 74 74 74 74\n"," 72  0 72 72 71 71 69 69 67 67 64 65 67  0 67 67 69 69 67 67 65 65 65 65\n"," 64 64 76 76 74 74 72 72 71 71 71 71 69 69 69 69 69 69  0  0 68 68 70 70\n"," 70 70 68 68]\n","Voice to target :\n","[ 0  0 57 57 50 52 53 53 52  0 52 50 48 48 52 52 45 45 57 57 56 56 57 57\n"," 52  0 52 52 57 57 55 55 48 48 53 55 57 57 59 59 60 59 57 55 53 53 55 55\n"," 48 48 45 45 50 52 53 53 47 47 48 48 60 58 57 55 53 52 50 49 50 50 50 50\n"," 44 44 45 45 47 47 48 50 52 52 40 40 45 45 45 45 45 45  0  0 56 56 54 54\n"," 54 54 49 49]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SvlOqRm3-_I7","colab_type":"code","outputId":"cb776fa8-4153-4e6f-9f56-0c0be39c0826","executionInfo":{"status":"ok","timestamp":1557498853966,"user_tz":-120,"elapsed":261,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# scale pianoroll to 0 \n","all_pianorolls_scaled = midi_utils.scale_pianoroll(all_pianorolls, global_lower)\n","print(\"Scaled voice to train on :\")\n","print(all_pianorolls_scaled[0:100])\n","all_pianorolls_scaled2 = midi_utils.scale_pianoroll(all_pianorolls2, global_lower)\n","print(\"Scaled voice to target :\")\n","print(all_pianorolls_scaled2[0:100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Scaled voice to train on :\n","[ 0  0 35  0 35  0 35 35 34 32 30 30 35 35 37 37 38  0 38 38 40 40 38 38\n"," 37  0 37 37 38 38 40 40 42 40 38 38 43  0 43 43 42 40 42 42 40 40 40 40\n"," 38  0 38 38 37 37 35 35 33 33 30 31 33  0 33 33 35 35 33 33 31 31 31 31\n"," 30 30 42 42 40 40 38 38 37 37 37 37 35 35 35 35 35 35  0  0 34 34 36 36\n"," 36 36 34 34]\n","Scaled voice to target :\n","[ 0  0 23 23 16 18 19 19 18  0 18 16 14 14 18 18 11 11 23 23 22 22 23 23\n"," 18  0 18 18 23 23 21 21 14 14 19 21 23 23 25 25 26 25 23 21 19 19 21 21\n"," 14 14 11 11 16 18 19 19 13 13 14 14 26 24 23 21 19 18 16 15 16 16 16 16\n"," 10 10 11 11 13 13 14 16 18 18  6  6 11 11 11 11 11 11  0  0 22 22 20 20\n"," 20 20 15 15]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAWv5b1A-_I8","colab_type":"code","outputId":"94b79202-bf78-4665-c29b-4690ff4c982a","executionInfo":{"status":"error","timestamp":1557500777449,"user_tz":-120,"elapsed":7814,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":653}},"source":["# Define and print the net\n","n_hidden=256\n","n_layers=2\n","\n","net_harmonization = NoteRNN(n_notes, n_hidden, n_layers)\n","print(net)\n","\n","# Declaring the hyperparameters\n","batch_size = 16\n","seq_length = 100\n","n_epochs = 50 # start smaller if you are just testing initial behavior\n","\n","# train the model\n","train(net_harmonization, data=all_pianorolls_scaled, data2=all_pianorolls_scaled2, mode=\"harmonization\", epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=50)"],"execution_count":166,"outputs":[{"output_type":"stream","text":["NoteRNN(\n","  (lstm): LSTM(50, 256, num_layers=2, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.5)\n","  (fc): Linear(in_features=256, out_features=50, bias=True)\n",")\n","[ 0  0 23 ... 14 14 21]\n","Epoch: 2/50... Step: 50... Loss: 2.8256... Val Loss: 2.9680\n","Epoch: 4/50... Step: 100... Loss: 2.4364... Val Loss: 2.6045\n","Epoch: 6/50... Step: 150... Loss: 1.4983... Val Loss: 1.6216\n","Epoch: 8/50... Step: 200... Loss: 0.4605... Val Loss: 0.5600\n","Epoch: 10/50... Step: 250... Loss: 0.1669... Val Loss: 0.2426\n","Epoch: 12/50... Step: 300... Loss: 0.0774... Val Loss: 0.1334\n","Epoch: 14/50... Step: 350... Loss: 0.0425... Val Loss: 0.0868\n","Epoch: 16/50... Step: 400... Loss: 0.0276... Val Loss: 0.0643\n","Epoch: 18/50... Step: 450... Loss: 0.0213... Val Loss: 0.0506\n","Epoch: 20/50... Step: 500... Loss: 0.0157... Val Loss: 0.0404\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-166-96347a79cf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_harmonization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_pianorolls_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_pianorolls_scaled2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"harmonization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-165-f38aa3f16b72>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, data, data2, mode, epochs, batch_size, seq_length, lr, clip, val_frac, print_every)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-119-f718191b4c6f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#get the outputs and the new hidden state from the lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mr_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#pass through a dropout layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aZW3uAKC4lMM","outputId":"26c8b0c5-72cd-4b3e-e264-e3440b7ca4b9","executionInfo":{"status":"ok","timestamp":1557500197010,"user_tz":-120,"elapsed":646,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# Generating harmonization\n","\n","# get one voice from the dataset \n","midi_filename = 'bwv14.5.mid'\n","csv_text = midi_utils.load_to_csv(midi_filename)\n","# get semitones to C major \n","semitones,_ = midi_utils.get_semitones_to_C(csv_text)\n","print('Semitones to C major : ' +str(semitones))\n","# get multitrack object from midi \n","multitrack = pypianoroll.parse(midi_filename, beat_resolution=2)\n","# get the soprano track\n","soprano_track = multitrack.tracks[0]\n","# transpose the track to C Major \n","soprano_track = pypianoroll.transpose(soprano_track,-semitones)\n","soprano_pianoroll = midi_utils.flatten_one_hot_pianoroll(soprano_track.pianoroll)\n","print('Soprano pianoroll :')\n","print(soprano_pianoroll)\n","scaled_soprano_pianoroll = midi_utils.scale_pianoroll(soprano_pianoroll, global_lower)\n","# now we can predict the second voice \n","scaled_alto_pianoroll = sample_harmonization(net_harmonization, scaled_soprano_pianoroll)\n","alto_pianoroll = midi_utils.unscale_pianoroll(scaled_alto_pianoroll, global_lower)\n","print('Alto pianoroll :')\n","print(alto_pianoroll)\n","one_hot_alto = midi_utils.one_hot_encode_pianoroll(alto_pianoroll, 128)*90\n","alto_track = Track(pianoroll=one_hot_alto, name='alto gernerated track')\n","# create a multitrack made of the initial soprano track and the generated alto\n","new_multitrack = Multitrack(tracks=[alto_track], tempo = 90, beat_resolution=2)\n","#write to midi file \n","pypianoroll.write(new_multitrack, home_dir + \"/results/RNN_harmonization_track\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Semitones to C major : -2\n","Soprano pianoroll :\n","[ 0  0 69 71 72 72 73 73 74 74 76 76 74 74 73 73 74  0 74 74 72 71 69 71\n"," 72 74 76 76 74 72 74 74 72 72 69 71 72 72 73 73 74 74 76 76 74 74 73 73\n"," 74  0 74 74 72 71 69 71 72 74 76 76 74 72 74 74 72 72 74 74 76 76 74 72\n"," 71 71 72 72 74 72 71 71 69  0 69 69 74 74 73 73 74 74 76 74 72 71 69 69\n"," 67  0 67 67 72 72 74 74 76 76 74 72 71 69 71 71 69 69]\n","Alto pianoroll :\n","[37  0 69 71 72 72 73 73 74 74 76 76 74 74 73 73 74  0 74 74 72 71 69 71\n"," 72 74 76 76 74 72 74 74 72 72 69 71 72 72 73 73 74 74 76 76 74 74 73 73\n"," 74  0 74 74 72 71 69 71 72 74 76 76 74 72 74 74 72 72 74 74 76 76 74 72\n"," 71 71 72 72 74 72 71 71 69  0 69 69 74 74 73 73 74 74 76 74 72 71 69 69\n"," 67  0 67 67 72 72 74 74 76 76 74 72 71 69 71 71 69 69]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D9c_NQ5q-_I-","colab_type":"code","outputId":"a2709ae9-0f11-4b21-e305-a740a4012685","executionInfo":{"status":"error","timestamp":1557498328917,"user_tz":-120,"elapsed":14282,"user":{"displayName":"Nicolas Deperrois","photoUrl":"https://lh5.googleusercontent.com/-Jfkdb6w84hk/AAAAAAAAAAI/AAAAAAAACRA/bqUAiv0shAM/s64/photo.jpg","userId":"11633758183366338150"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["modified_midi_filename = home_dir + \"/results/RNN_harmonization_track.mid\"\n","pygame.init()\n","pygame.mixer.music.load(modified_midi_filename)\n","pygame.mixer.music.play()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-103-b59c140a6544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodified_midi_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/results/RNN_harmonization_track.mid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_midi_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: mixer not initialized"]}]},{"cell_type":"code","metadata":{"id":"MpStKEvO-_I-","colab_type":"code","colab":{}},"source":["pygame.mixer.music.stop()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"562Tt2rR-_I_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}