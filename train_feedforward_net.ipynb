{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train feedforward net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below and run this cell to get your data from github into colab (only runnable in colab, not ordinary jupyter notebook):\n",
    "#! git clone https://github.com/lkriener/music_generation.git && mv music_generation/* . && rm music_generation -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import src.midi_utils as midi_utils\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_filename = 'midi_data/bwv104.6.mid'\n",
    "# midi_filename = 'midi_data/pkgsc_azalea.mid'\n",
    "pygame.init()\n",
    "pygame.mixer.music.load(midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 357\n",
      "Mean of the dataset: 70.56518791895759\n",
      "Number of samples: 13277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\ml-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "label_scaler = StandardScaler()\n",
    "\n",
    "tracks = []\n",
    "# iterate over all midi files of folder\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    home_dir\n",
    "except NameError:\n",
    "    home_dir = os.getcwd()\n",
    "\n",
    "os.chdir(home_dir + \"/midi_data/bach\")  # go to a folder relative to home dir\n",
    "for midi_file in glob.glob(\"*.mid\"):\n",
    "    # get a list of all soprano tracks\n",
    "    ## load midi file\n",
    "    csv_text = midi_utils.load_to_csv(midi_file)\n",
    "\n",
    "    ## Split into tracks\n",
    "    track_dict = midi_utils.split_tracks(csv_text)\n",
    "    track_nr = '1'\n",
    "\n",
    "    ## Generating numpy array with notes\n",
    "    track = midi_utils.midi_track_to_numpy(track_dict[track_nr])\n",
    "    tracks.append(track)\n",
    "    \n",
    "print(\"Number of tracks: \" + str(len(tracks)))\n",
    "\n",
    "x, y = get_dataset_representation_from_tracks(tracks, feature_qty=20, prediction_qty=2)\n",
    "\n",
    "# drop length of notes and keep pitch\n",
    "x = np.stack(x)\n",
    "x = x[:,:,0]\n",
    "\n",
    "y = np.stack(y)\n",
    "y = y[:,:,0]\n",
    "\n",
    "feature_scaler.fit(x)\n",
    "\n",
    "print(\"Mean of the dataset: \" + str(feature_scaler.mean_[0]))\n",
    "\n",
    "x = feature_scaler.fit_transform(x)\n",
    "\n",
    "label_scaler.fit(y)\n",
    "\n",
    "y = label_scaler.fit_transform(y)\n",
    "\n",
    "print(\"Number of samples: \" + str(len(x)))\n",
    "\n",
    "mini_batch_size = 32\n",
    "\n",
    "# for now, we only train on the pitches of the notes\n",
    "train_dataset = TrackDataset(x, y, drop_length=False)  # make training dataset\n",
    "#validation_dataset = TrackDataset(val_images, val_centers)  # make validation dataset\n",
    "#test_dataset = TrackDataset(test_images, test_centers)  # make test dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True) # TODO TODO TODO: CHANGE TO A SUITABLE VALIDATIONSET\n",
    "#test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 13277\n",
      "Input size 20/ output size 2/ learning rate 0.001\n",
      "Input example tensor([ 0.9796,  1.8240,  0.9512,  0.9406,  0.9328,  0.9315,  1.2167,  0.9348,\n",
      "         0.3699,  0.3700, -0.1906,  0.9375,  1.7837,  0.3825,  0.3826,  0.3806,\n",
      "        -1.0221, -0.1851, -0.4686, -1.0288])\n",
      "Output example tensor([0.9344, 1.7809])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training set size\", len(train_dataset))\n",
    "\n",
    "input_size = len(train_dataset[0][0])  # get input size\n",
    "input_example = train_dataset[0][0]\n",
    "output_size = len(train_dataset[0][1])  # get output size\n",
    "output_example = train_dataset[0][1]\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Input size {}/ output size {}/ learning rate {}\".format(input_size, output_size, learning_rate))\n",
    "print(\"Input example {}\".format(input_example))\n",
    "print(\"Output example {}\".format(output_example))\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dimension, output_dimension, bias=True)  # linear layer with parameters A, b\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = self.fc(input_data)  # applies out = input * A + b. A, b are parameters of nn.Linear that we want to learn\n",
    "        return output\n",
    "    \n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "    \n",
    "# linear_model = LinearModel(input_size, output_size)\n",
    "# \n",
    "# linear_model = linear_model.to(device)\n",
    "# \n",
    "mlp_model = MLPModel(input_size, 256, output_size)\n",
    "\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "model = mlp_model\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device=torch.device('cpu'), verbose=1):\n",
    "    # We will monitor loss functions as the training progresses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # training phase\n",
    "        model.train()\n",
    "        # Iterate mini batches over training dataset\n",
    "        losses = []\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)  # predict output from input\n",
    "            \n",
    "            # set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            if verbose > 2:\n",
    "                print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        # iterate mini batches over validation set\n",
    "        # We don't need gradients\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_function(output, y)\n",
    "                if verbose > 1:\n",
    "                    print(loss.item())\n",
    "\n",
    "                losses.append(loss.item())\n",
    "        val_losses.append(np.mean(np.array(losses)))\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Epoch {}/{}: train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, n_epochs, train_losses[-1], val_losses[-1]))\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: train_loss: 0.5295, val_loss: 0.4991\n",
      "Epoch 2/50: train_loss: 0.4995, val_loss: 0.4808\n",
      "Epoch 3/50: train_loss: 0.4892, val_loss: 0.4673\n",
      "Epoch 4/50: train_loss: 0.4794, val_loss: 0.4663\n",
      "Epoch 5/50: train_loss: 0.4673, val_loss: 0.4410\n",
      "Epoch 6/50: train_loss: 0.4525, val_loss: 0.4262\n",
      "Epoch 7/50: train_loss: 0.4382, val_loss: 0.4129\n",
      "Epoch 8/50: train_loss: 0.4190, val_loss: 0.4038\n",
      "Epoch 9/50: train_loss: 0.4014, val_loss: 0.3705\n",
      "Epoch 10/50: train_loss: 0.3828, val_loss: 0.3473\n",
      "Epoch 11/50: train_loss: 0.3640, val_loss: 0.3280\n",
      "Epoch 12/50: train_loss: 0.3417, val_loss: 0.3030\n",
      "Epoch 13/50: train_loss: 0.3210, val_loss: 0.2809\n",
      "Epoch 14/50: train_loss: 0.2994, val_loss: 0.2673\n",
      "Epoch 15/50: train_loss: 0.2799, val_loss: 0.2526\n",
      "Epoch 16/50: train_loss: 0.2601, val_loss: 0.2248\n",
      "Epoch 17/50: train_loss: 0.2384, val_loss: 0.2147\n",
      "Epoch 18/50: train_loss: 0.2225, val_loss: 0.1823\n",
      "Epoch 19/50: train_loss: 0.2052, val_loss: 0.1763\n",
      "Epoch 20/50: train_loss: 0.1914, val_loss: 0.1653\n",
      "Epoch 21/50: train_loss: 0.1733, val_loss: 0.1514\n",
      "Epoch 22/50: train_loss: 0.1632, val_loss: 0.1355\n",
      "Epoch 23/50: train_loss: 0.1490, val_loss: 0.1319\n",
      "Epoch 24/50: train_loss: 0.1392, val_loss: 0.1214\n",
      "Epoch 25/50: train_loss: 0.1305, val_loss: 0.1134\n",
      "Epoch 26/50: train_loss: 0.1221, val_loss: 0.1048\n",
      "Epoch 27/50: train_loss: 0.1131, val_loss: 0.1203\n",
      "Epoch 28/50: train_loss: 0.1091, val_loss: 0.0918\n",
      "Epoch 29/50: train_loss: 0.1014, val_loss: 0.0852\n",
      "Epoch 30/50: train_loss: 0.0966, val_loss: 0.0836\n",
      "Epoch 31/50: train_loss: 0.0906, val_loss: 0.0781\n",
      "Epoch 32/50: train_loss: 0.0853, val_loss: 0.0747\n",
      "Epoch 33/50: train_loss: 0.0806, val_loss: 0.0701\n",
      "Epoch 34/50: train_loss: 0.0784, val_loss: 0.0738\n",
      "Epoch 35/50: train_loss: 0.0763, val_loss: 0.0653\n",
      "Epoch 36/50: train_loss: 0.0706, val_loss: 0.0676\n",
      "Epoch 37/50: train_loss: 0.0713, val_loss: 0.0592\n",
      "Epoch 38/50: train_loss: 0.0697, val_loss: 0.0649\n",
      "Epoch 39/50: train_loss: 0.0652, val_loss: 0.0603\n",
      "Epoch 40/50: train_loss: 0.0626, val_loss: 0.0596\n",
      "Epoch 41/50: train_loss: 0.0613, val_loss: 0.0618\n",
      "Epoch 42/50: train_loss: 0.0626, val_loss: 0.0534\n",
      "Epoch 43/50: train_loss: 0.0567, val_loss: 0.0565\n",
      "Epoch 44/50: train_loss: 0.0580, val_loss: 0.0536\n",
      "Epoch 45/50: train_loss: 0.0546, val_loss: 0.0471\n",
      "Epoch 46/50: train_loss: 0.0541, val_loss: 0.0479\n",
      "Epoch 47/50: train_loss: 0.0511, val_loss: 0.0496\n",
      "Epoch 48/50: train_loss: 0.0516, val_loss: 0.0508\n",
      "Epoch 49/50: train_loss: 0.0506, val_loss: 0.0469\n",
      "Epoch 50/50: train_loss: 0.0510, val_loss: 0.0483\n"
     ]
    }
   ],
   "source": [
    "# Train the linear model and plot how the loss changes as the \n",
    "# training progresses for both training and validation set.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, validation_loader, optimizer, 50, criterion, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67. 65. 67. 66.]\n",
      " [62. 62. 62. 62.]\n",
      " [73. 73. 72. 72.]\n",
      " [67. 65. 67. 65.]\n",
      " [78. 76. 76. 77.]\n",
      " [69. 71. 69. 71.]\n",
      " [74. 72. 75. 72.]\n",
      " [74. 73. 74. 73.]\n",
      " [71. 69. 71. 68.]\n",
      " [66. 68. 66. 68.]\n",
      " [67. 69. 68. 69.]\n",
      " [71. 69. 71. 69.]\n",
      " [67. 67. 68. 68.]\n",
      " [74. 72. 75. 71.]\n",
      " [65. 64. 65. 64.]\n",
      " [76. 74. 76. 74.]\n",
      " [64. 66. 63. 66.]\n",
      " [74. 76. 74. 76.]\n",
      " [66. 64. 66. 64.]\n",
      " [74. 72. 74. 72.]\n",
      " [64. 64. 65. 64.]\n",
      " [66. 64. 67. 65.]\n",
      " [74. 73. 72. 73.]\n",
      " [65. 64. 66. 65.]\n",
      " [69. 67. 70. 68.]\n",
      " [76. 74. 77. 74.]\n",
      " [69. 67. 69. 68.]\n",
      " [74. 76. 75. 76.]\n",
      " [74. 74. 74. 74.]\n",
      " [72. 74. 72. 74.]\n",
      " [72. 69. 72. 69.]\n",
      " [71. 69. 73. 70.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check predictions from samples\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(x)  # predict output from input\n",
    "    \n",
    "    scaled_y = label_scaler.inverse_transform(y.detach().numpy())\n",
    "    scaled_output = label_scaler.inverse_transform(output.detach().numpy())\n",
    "\n",
    "    print(np.concatenate((scaled_y, np.round(scaled_output)), axis=1))\n",
    "    break\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "x = range(len(train_losses))\n",
    "plt.plot(x, train_losses, x, val_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72. 70. 72. 74. 72. 70. 69. 70. 72. 70. 69. 67. 67. 72. 71. 72. 74. 72.\n",
      " 70. 69. 67. 65. 66. 70. 71. 74. 74. 73. 72. 72. 71. 73. 76. 77. 76. 74.\n",
      " 73. 73. 74. 73. 70. 71. 73. 72. 72. 71. 69. 70. 72. 72. 72. 73. 75. 75.\n",
      " 74. 73. 73. 72. 71. 68. 71. 72. 74. 73. 71. 71. 73. 73. 74. 74. 71. 71.\n",
      " 72. 71. 70. 71. 72. 72. 72. 71.]\n"
     ]
    }
   ],
   "source": [
    "# predict midi from init samples\n",
    "\n",
    "init_index = 1000\n",
    "\n",
    "generated_track = train_dataset[init_index][0].clone()\n",
    "\n",
    "# predict for a certain length\n",
    "predict_length = 30  # TODO: Model the end of the songs as well through a terminator.\n",
    "\n",
    "x, y = train_dataset[init_index]\n",
    "x = x.to(device)\n",
    "for i in range(predict_length):\n",
    "    _, y = train_dataset[init_index + i]\n",
    "    y = y.to(device)\n",
    "    output = model(x)  # predict output from input\n",
    "    x = torch.cat((x[output.shape[0]:], output))  # shift the input by one by adding the prediction\n",
    "    generated_track = torch.cat((generated_track, output))  # append prediction to generated track\n",
    "    \n",
    "#print(generated_track.detach().numpy())\n",
    "    \n",
    "n_generated_track = generated_track.detach().numpy()\n",
    "n_generated_track = n_generated_track.reshape(int(n_generated_track.shape[0]/output.shape[0]), output.shape[0])\n",
    "track = label_scaler.inverse_transform(n_generated_track).round().flatten()\n",
    "\n",
    "print(track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write numpy to midi track\n",
    "\n",
    "numpy_notes = midi_utils.prediction_to_numpy(track, 1024)\n",
    "\n",
    "# create midi track\n",
    "new_track = midi_utils.numpy_to_midi_track(numpy_notes, 1, 'Modified')\n",
    "\n",
    "#print(numpy_notes)\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "# make new song with the new track\n",
    "new_track_dict = {}\n",
    "new_track_dict['0'] = track_dict['0']\n",
    "new_track_dict['1'] = new_track\n",
    "modified_midi_filename = 'midi_data/test_modified_track.mid'\n",
    "modified_csv_list = midi_utils.track_dict_to_csv(new_track_dict)\n",
    "midi_utils.write_to_midi(modified_csv_list, modified_midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "pygame.mixer.music.load(modified_midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
