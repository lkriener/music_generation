{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train feedforward net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import src.midi_utils as midi_utils\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_filename = 'midi_data/bwv104.6.mid'\n",
    "# midi_filename = 'midi_data/pkgsc_azalea.mid'\n",
    "pygame.init()\n",
    "pygame.mixer.music.load(midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 357\n",
      "Number of samples: 17204\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tracks = []\n",
    "# iterate over all midi files of folder\n",
    "import glob\n",
    "import os\n",
    "\n",
    "try:\n",
    "    home_dir\n",
    "except NameError:\n",
    "    home_dir = os.getcwd()\n",
    "\n",
    "os.chdir(home_dir + \"/midi_data/bach\")  # go to a folder relative to home dir\n",
    "for midi_file in glob.glob(\"*.mid\"):\n",
    "    # get a list of all soprano tracks\n",
    "    ## load midi file\n",
    "    csv_text = midi_utils.load_to_csv(midi_file)\n",
    "\n",
    "    ## Split into tracks\n",
    "    track_dict = midi_utils.split_tracks(csv_text)\n",
    "    track_nr = '1'\n",
    "\n",
    "    ## Generating numpy array with notes\n",
    "    track = midi_utils.midi_track_to_numpy(track_dict[track_nr])\n",
    "    tracks.append(track)\n",
    "    \n",
    "print(\"Number of tracks: \" + str(len(tracks)))\n",
    "\n",
    "x, y = get_dataset_representation_from_tracks(tracks)\n",
    "\n",
    "print(\"Number of samples: \" + str(len(x)))\n",
    "\n",
    "mini_batch_size = 32\n",
    "\n",
    "# for now, we only train on the pitches of the notes\n",
    "train_dataset = TrackDataset(x, y, drop_length=True)  # make training dataset\n",
    "#validation_dataset = TrackDataset(val_images, val_centers)  # make validation dataset\n",
    "#test_dataset = TrackDataset(test_images, test_centers)  # make test dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True) # TODO TODO TODO: CHANGE TO A SUITABLE VALIDATIONSET\n",
    "#test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 17204\n",
      "Input size 10/ output size 1/ learning rate 0.0001\n",
      "Input example tensor([74., 77., 74., 74., 74., 74., 75., 74., 72., 72.])\n",
      "Output example tensor([70.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training set size\", len(train_dataset))\n",
    "\n",
    "input_size = len(train_dataset[0][0])  # get input size\n",
    "input_example = train_dataset[0][0]\n",
    "output_size = len(train_dataset[0][1])  # get output size\n",
    "output_example = train_dataset[0][1]\n",
    "learning_rate = 0.0001\n",
    "\n",
    "print(\"Input size {}/ output size {}/ learning rate {}\".format(input_size, output_size, learning_rate))\n",
    "print(\"Input example {}\".format(input_example))\n",
    "print(\"Output example {}\".format(output_example))\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dimension, output_dimension, bias=True)  # linear layer with parameters A, b\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = self.fc(input_data)  # applies out = input * A + b. A, b are parameters of nn.Linear that we want to learn\n",
    "        return output\n",
    "    \n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "    \n",
    "# linear_model = LinearModel(input_size, output_size)\n",
    "# \n",
    "# linear_model = linear_model.to(device)\n",
    "# \n",
    "mlp_model = MLPModel(input_size, 64, output_size)\n",
    "\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "model = mlp_model\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device=torch.device('cpu'), verbose=1):\n",
    "    # We will monitor loss functions as the training progresses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # training phase\n",
    "        model.train()\n",
    "        # Iterate mini batches over training dataset\n",
    "        losses = []\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)  # predict output from input\n",
    "            \n",
    "            # set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            if verbose > 2:\n",
    "                print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        # iterate mini batches over validation set\n",
    "        # We don't need gradients\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_function(output, y)\n",
    "                if verbose > 1:\n",
    "                    print(loss.item())\n",
    "\n",
    "                losses.append(loss.item())\n",
    "        val_losses.append(np.mean(np.array(losses)))\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Epoch {}/{}: train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, n_epochs, train_losses[-1], val_losses[-1]))\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: train_loss: 6305.8225, val_loss: 4073.2958\n",
      "Epoch 2/50: train_loss: 3666.7885, val_loss: 3286.9889\n",
      "Epoch 3/50: train_loss: 2959.0862, val_loss: 2653.0380\n",
      "Epoch 4/50: train_loss: 2388.7364, val_loss: 2141.6806\n",
      "Epoch 5/50: train_loss: 1928.5474, val_loss: 1729.4296\n",
      "Epoch 6/50: train_loss: 1557.6488, val_loss: 1397.0180\n",
      "Epoch 7/50: train_loss: 1258.4068, val_loss: 1129.0132\n",
      "Epoch 8/50: train_loss: 1017.1944, val_loss: 912.7777\n",
      "Epoch 9/50: train_loss: 822.6472, val_loss: 738.5246\n",
      "Epoch 10/50: train_loss: 665.8573, val_loss: 597.9620\n",
      "Epoch 11/50: train_loss: 539.3505, val_loss: 484.6309\n",
      "Epoch 12/50: train_loss: 437.3793, val_loss: 393.2572\n",
      "Epoch 13/50: train_loss: 355.1409, val_loss: 319.5581\n",
      "Epoch 14/50: train_loss: 288.8403, val_loss: 260.1792\n",
      "Epoch 15/50: train_loss: 235.3840, val_loss: 212.2423\n",
      "Epoch 16/50: train_loss: 192.2664, val_loss: 173.5866\n",
      "Epoch 17/50: train_loss: 157.4595, val_loss: 142.4225\n",
      "Epoch 18/50: train_loss: 129.4410, val_loss: 117.3084\n",
      "Epoch 19/50: train_loss: 106.8247, val_loss: 97.0337\n",
      "Epoch 20/50: train_loss: 88.6006, val_loss: 80.7126\n",
      "Epoch 21/50: train_loss: 73.8928, val_loss: 67.5433\n",
      "Epoch 22/50: train_loss: 62.0418, val_loss: 56.9178\n",
      "Epoch 23/50: train_loss: 52.4939, val_loss: 48.3624\n",
      "Epoch 24/50: train_loss: 44.7830, val_loss: 41.4529\n",
      "Epoch 25/50: train_loss: 38.5749, val_loss: 35.8770\n",
      "Epoch 26/50: train_loss: 33.5528, val_loss: 31.3912\n",
      "Epoch 27/50: train_loss: 29.5197, val_loss: 27.7655\n",
      "Epoch 28/50: train_loss: 26.2580, val_loss: 24.8465\n",
      "Epoch 29/50: train_loss: 23.6369, val_loss: 22.4908\n",
      "Epoch 30/50: train_loss: 21.5113, val_loss: 20.6000\n",
      "Epoch 31/50: train_loss: 19.8046, val_loss: 19.0589\n",
      "Epoch 32/50: train_loss: 18.4293, val_loss: 17.8278\n",
      "Epoch 33/50: train_loss: 17.3148, val_loss: 16.8357\n",
      "Epoch 34/50: train_loss: 16.4173, val_loss: 16.0244\n",
      "Epoch 35/50: train_loss: 15.6942, val_loss: 15.3846\n",
      "Epoch 36/50: train_loss: 15.1092, val_loss: 14.8588\n",
      "Epoch 37/50: train_loss: 14.6442, val_loss: 14.4402\n",
      "Epoch 38/50: train_loss: 14.2611, val_loss: 14.0997\n",
      "Epoch 39/50: train_loss: 13.9555, val_loss: 13.8288\n",
      "Epoch 40/50: train_loss: 13.7138, val_loss: 13.6067\n",
      "Epoch 41/50: train_loss: 13.5137, val_loss: 13.4264\n",
      "Epoch 42/50: train_loss: 13.3529, val_loss: 13.2815\n",
      "Epoch 43/50: train_loss: 13.2220, val_loss: 13.1709\n",
      "Epoch 44/50: train_loss: 13.1229, val_loss: 13.0731\n",
      "Epoch 45/50: train_loss: 13.0374, val_loss: 12.9989\n",
      "Epoch 46/50: train_loss: 12.9643, val_loss: 12.9377\n",
      "Epoch 47/50: train_loss: 12.9087, val_loss: 12.8914\n",
      "Epoch 48/50: train_loss: 12.8683, val_loss: 12.8535\n",
      "Epoch 49/50: train_loss: 12.8363, val_loss: 12.8211\n",
      "Epoch 50/50: train_loss: 12.8074, val_loss: 12.7912\n"
     ]
    }
   ],
   "source": [
    "# Train the linear model and plot how the loss changes as the \n",
    "# training progresses for both training and validation set.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, validation_loader, optimizer, 50, criterion, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[67., 69., 67., 66., 66., 66., 67., 67., 69., 69.],\n",
      "        [73., 71., 73., 66., 68., 69., 71., 69., 74., 74.],\n",
      "        [71., 73., 75., 76., 76., 78., 75., 76., 76., 76.],\n",
      "        [74., 72., 70., 72., 72., 74., 70., 72., 74., 75.],\n",
      "        [74., 70., 79., 75., 77., 70., 75., 72., 70., 72.],\n",
      "        [74., 75., 74., 72., 74., 67., 72., 70., 69., 70.],\n",
      "        [74., 76., 74., 69., 74., 72., 70., 69., 67., 69.],\n",
      "        [69., 67., 67., 69., 67., 66., 66., 66., 67., 67.],\n",
      "        [76., 78., 76., 74., 73., 74., 73., 71., 71., 76.],\n",
      "        [76., 71., 72., 69., 69., 64., 65., 64., 69., 68.],\n",
      "        [70., 69., 67., 69., 65., 65., 70., 69., 67., 65.],\n",
      "        [74., 74., 69., 71., 73., 74., 73., 71., 69., 74.],\n",
      "        [71., 69., 71., 68., 68., 69., 71., 73., 71., 73.],\n",
      "        [67., 69., 70., 69., 67., 65., 67., 69., 67., 69.],\n",
      "        [74., 72., 71., 71., 69., 72., 72., 71., 69., 68.],\n",
      "        [78., 78., 76., 71., 71., 72., 71., 69., 69., 67.],\n",
      "        [70., 68., 67., 72., 72., 70., 75., 74., 72., 70.],\n",
      "        [75., 74., 72., 74., 70., 74., 75., 74., 72., 72.],\n",
      "        [69., 67., 72., 74., 72., 71., 69., 67., 69., 71.],\n",
      "        [72., 70., 72., 70., 72., 74., 72., 70., 69., 70.],\n",
      "        [76., 74., 71., 71., 72., 74., 76., 76., 74., 72.],\n",
      "        [66., 67., 69., 71., 69., 74., 73., 71., 71., 76.],\n",
      "        [73., 71., 73., 71., 71., 73., 74., 76., 74., 76.],\n",
      "        [72., 74., 76., 74., 76., 72., 71., 69., 71., 69.],\n",
      "        [65., 63., 63., 63., 65., 67., 65., 63., 67., 69.],\n",
      "        [69., 68., 66., 64., 64., 69., 71., 73., 71., 73.],\n",
      "        [72., 70., 70., 70., 72., 72., 70., 68., 67., 67.],\n",
      "        [69., 71., 73., 74., 73., 71., 69., 71., 69., 68.],\n",
      "        [74., 73., 71., 69., 71., 69., 68., 66., 64., 66.],\n",
      "        [67., 69., 67., 66., 62., 69., 72., 70., 69., 70.],\n",
      "        [81., 79., 77., 76., 74., 76., 79., 77., 76., 74.],\n",
      "        [71., 69., 71., 72., 71., 69., 76., 76., 74., 72.]])\n",
      "\n",
      "\n",
      "tensor([[71.],\n",
      "        [73.],\n",
      "        [76.],\n",
      "        [77.],\n",
      "        [75.],\n",
      "        [72.],\n",
      "        [76.],\n",
      "        [69.],\n",
      "        [74.],\n",
      "        [69.],\n",
      "        [72.],\n",
      "        [73.],\n",
      "        [74.],\n",
      "        [71.],\n",
      "        [69.],\n",
      "        [71.],\n",
      "        [68.],\n",
      "        [70.],\n",
      "        [72.],\n",
      "        [72.],\n",
      "        [71.],\n",
      "        [78.],\n",
      "        [78.],\n",
      "        [69.],\n",
      "        [70.],\n",
      "        [74.],\n",
      "        [70.],\n",
      "        [66.],\n",
      "        [68.],\n",
      "        [70.],\n",
      "        [72.],\n",
      "        [71.]])\n",
      "71.90625\n",
      "\n",
      "\n",
      "tensor([[70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747],\n",
      "        [70.2747]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check predictions from samples\n",
    "\n",
    "for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(x)  # predict output from input\n",
    "\n",
    "    print(x)\n",
    "    print(\"\\n\")\n",
    "    print(y)\n",
    "    print(torch.mean(y).item())\n",
    "    print(\"\\n\")\n",
    "    print(output)\n",
    "    break\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "x = range(len(train_losses))\n",
    "plt.plot(x, train_losses, x, val_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74. 77. 74. 74. 74. 74. 75. 74. 72. 72. 70. 70. 70. 70. 70. 70. 70. 70.\n",
      " 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70. 70.\n",
      " 70. 70. 70. 70.]\n"
     ]
    }
   ],
   "source": [
    "# predict midi from init samples\n",
    "\n",
    "init_sample, _ = train_dataset[0]  # some sample\n",
    "x = init_sample.to(device)\n",
    "\n",
    "generated_track = x.clone()\n",
    "\n",
    "# predict for a certain length\n",
    "predict_length = 30  # TODO: Model the end of the songs as well through a terminator.\n",
    "\n",
    "for i in range(predict_length):\n",
    "    y = model(x)  # predict output from input\n",
    "    x = torch.cat((x[1:], y))  # shift the input by one by adding the prediction\n",
    "    generated_track = torch.cat((generated_track, y.round()))  # append prediction to generated track\n",
    "    \n",
    "track = generated_track.detach().numpy()\n",
    "\n",
    "print(track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  74. 1024.]\n",
      " [  77. 1024.]\n",
      " [  74. 1024.]\n",
      " [  74. 1024.]\n",
      " [  74. 1024.]\n",
      " [  74. 1024.]\n",
      " [  75. 1024.]\n",
      " [  74. 1024.]\n",
      " [  72. 1024.]\n",
      " [  72. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]\n",
      " [  70. 1024.]]\n"
     ]
    }
   ],
   "source": [
    "# write numpy to midi track\n",
    "\n",
    "numpy_notes = midi_utils.prediction_to_numpy(track, 1024)\n",
    "\n",
    "# create midi track\n",
    "new_track = midi_utils.numpy_to_midi_track(numpy_notes, 1, 'Modified')\n",
    "\n",
    "print(numpy_notes)\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "# make new song with the new track\n",
    "new_track_dict = {}\n",
    "new_track_dict['0'] = track_dict['0']\n",
    "new_track_dict['1'] = new_track\n",
    "modified_midi_filename = 'midi_data/test_modified_track.mid'\n",
    "modified_csv_list = midi_utils.track_dict_to_csv(new_track_dict)\n",
    "midi_utils.write_to_midi(modified_csv_list, modified_midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "pygame.mixer.music.load(modified_midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
