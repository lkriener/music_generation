{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train feedforward net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import src.midi_utils as midi_utils\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_filename = 'midi_data/bwv104.6.mid'\n",
    "# midi_filename = 'midi_data/pkgsc_azalea.mid'\n",
    "pygame.init()\n",
    "pygame.mixer.music.load(midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 357\n",
      "Mean of the dataset: [70.56518792 70.62664759 70.66822324 70.69465994 70.71220908 70.71168186\n",
      " 70.70527981 70.69315357 70.68999021 70.68727875 70.67831588 70.66302629\n",
      " 70.64992092 70.63568577 70.63478195 70.64261505 70.65157792 70.66159524\n",
      " 70.67432402 70.67567975]\n",
      "Number of samples: 13277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "label_scaler = StandardScaler()\n",
    "\n",
    "tracks = []\n",
    "# iterate over all midi files of folder\n",
    "import glob\n",
    "import os\n",
    "\n",
    "try:\n",
    "    home_dir\n",
    "except NameError:\n",
    "    home_dir = os.getcwd()\n",
    "\n",
    "os.chdir(home_dir + \"/midi_data/bach\")  # go to a folder relative to home dir\n",
    "for midi_file in glob.glob(\"*.mid\"):\n",
    "    # get a list of all soprano tracks\n",
    "    ## load midi file\n",
    "    csv_text = midi_utils.load_to_csv(midi_file)\n",
    "\n",
    "    ## Split into tracks\n",
    "    track_dict = midi_utils.split_tracks(csv_text)\n",
    "    track_nr = '1'\n",
    "\n",
    "    ## Generating numpy array with notes\n",
    "    track = midi_utils.midi_track_to_numpy(track_dict[track_nr])\n",
    "    tracks.append(track)\n",
    "    \n",
    "print(\"Number of tracks: \" + str(len(tracks)))\n",
    "\n",
    "x, y = get_dataset_representation_from_tracks(tracks, feature_qty=20, prediction_qty=2)\n",
    "\n",
    "x = np.stack(x)\n",
    "x = x[:,:,0]\n",
    "\n",
    "y = np.stack(y)\n",
    "y = y[:,:,0]\n",
    "\n",
    "feature_scaler.fit(x)\n",
    "\n",
    "print(\"Mean of the dataset: \" + str(feature_scaler.mean_))\n",
    "\n",
    "x = feature_scaler.fit_transform(x)\n",
    "\n",
    "label_scaler.fit(y)\n",
    "\n",
    "y = label_scaler.fit_transform(y)\n",
    "\n",
    "\n",
    "print(\"Number of samples: \" + str(len(x)))\n",
    "\n",
    "mini_batch_size = 32\n",
    "\n",
    "# for now, we only train on the pitches of the notes\n",
    "train_dataset = TrackDataset(x, y, drop_length=False)  # make training dataset\n",
    "#validation_dataset = TrackDataset(val_images, val_centers)  # make validation dataset\n",
    "#test_dataset = TrackDataset(test_images, test_centers)  # make test dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True) # TODO TODO TODO: CHANGE TO A SUITABLE VALIDATIONSET\n",
    "#test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 13277\n",
      "Input size 20/ output size 2/ learning rate 0.001\n",
      "Input example tensor([ 0.9796,  1.8240,  0.9512,  0.9406,  0.9328,  0.9315,  1.2167,  0.9348,\n",
      "         0.3699,  0.3700, -0.1906,  0.9375,  1.7837,  0.3825,  0.3826,  0.3806,\n",
      "        -1.0221, -0.1851, -0.4686, -1.0288])\n",
      "Output example tensor([0.9344, 1.7809])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training set size\", len(train_dataset))\n",
    "\n",
    "input_size = len(train_dataset[0][0])  # get input size\n",
    "input_example = train_dataset[0][0]\n",
    "output_size = len(train_dataset[0][1])  # get output size\n",
    "output_example = train_dataset[0][1]\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Input size {}/ output size {}/ learning rate {}\".format(input_size, output_size, learning_rate))\n",
    "print(\"Input example {}\".format(input_example))\n",
    "print(\"Output example {}\".format(output_example))\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dimension, output_dimension, bias=True)  # linear layer with parameters A, b\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = self.fc(input_data)  # applies out = input * A + b. A, b are parameters of nn.Linear that we want to learn\n",
    "        return output\n",
    "    \n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "    \n",
    "# linear_model = LinearModel(input_size, output_size)\n",
    "# \n",
    "# linear_model = linear_model.to(device)\n",
    "# \n",
    "mlp_model = MLPModel(input_size, 256, output_size)\n",
    "\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "model = mlp_model\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device=torch.device('cpu'), verbose=1):\n",
    "    # We will monitor loss functions as the training progresses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # training phase\n",
    "        model.train()\n",
    "        # Iterate mini batches over training dataset\n",
    "        losses = []\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)  # predict output from input\n",
    "            \n",
    "            # set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            if verbose > 2:\n",
    "                print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        # iterate mini batches over validation set\n",
    "        # We don't need gradients\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_function(output, y)\n",
    "                if verbose > 1:\n",
    "                    print(loss.item())\n",
    "\n",
    "                losses.append(loss.item())\n",
    "        val_losses.append(np.mean(np.array(losses)))\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Epoch {}/{}: train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, n_epochs, train_losses[-1], val_losses[-1]))\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: train_loss: 0.5319, val_loss: 0.4928\n",
      "Epoch 2/50: train_loss: 0.5008, val_loss: 0.4972\n",
      "Epoch 3/50: train_loss: 0.4897, val_loss: 0.4674\n",
      "Epoch 4/50: train_loss: 0.4764, val_loss: 0.4611\n",
      "Epoch 5/50: train_loss: 0.4648, val_loss: 0.4411\n",
      "Epoch 6/50: train_loss: 0.4531, val_loss: 0.4305\n",
      "Epoch 7/50: train_loss: 0.4362, val_loss: 0.4183\n",
      "Epoch 8/50: train_loss: 0.4197, val_loss: 0.3853\n",
      "Epoch 9/50: train_loss: 0.4052, val_loss: 0.3719\n",
      "Epoch 10/50: train_loss: 0.3848, val_loss: 0.3476\n",
      "Epoch 11/50: train_loss: 0.3621, val_loss: 0.3314\n",
      "Epoch 12/50: train_loss: 0.3476, val_loss: 0.3133\n",
      "Epoch 13/50: train_loss: 0.3268, val_loss: 0.2837\n",
      "Epoch 14/50: train_loss: 0.3047, val_loss: 0.2701\n",
      "Epoch 15/50: train_loss: 0.2835, val_loss: 0.2525\n",
      "Epoch 16/50: train_loss: 0.2665, val_loss: 0.2326\n",
      "Epoch 17/50: train_loss: 0.2459, val_loss: 0.2218\n",
      "Epoch 18/50: train_loss: 0.2305, val_loss: 0.1945\n",
      "Epoch 19/50: train_loss: 0.2141, val_loss: 0.1892\n",
      "Epoch 20/50: train_loss: 0.1983, val_loss: 0.1766\n",
      "Epoch 21/50: train_loss: 0.1852, val_loss: 0.1548\n",
      "Epoch 22/50: train_loss: 0.1694, val_loss: 0.1555\n",
      "Epoch 23/50: train_loss: 0.1573, val_loss: 0.1393\n",
      "Epoch 24/50: train_loss: 0.1484, val_loss: 0.1384\n",
      "Epoch 25/50: train_loss: 0.1348, val_loss: 0.1208\n",
      "Epoch 26/50: train_loss: 0.1265, val_loss: 0.1093\n",
      "Epoch 27/50: train_loss: 0.1201, val_loss: 0.1071\n",
      "Epoch 28/50: train_loss: 0.1109, val_loss: 0.0977\n",
      "Epoch 29/50: train_loss: 0.1046, val_loss: 0.0935\n",
      "Epoch 30/50: train_loss: 0.0999, val_loss: 0.0974\n",
      "Epoch 31/50: train_loss: 0.0957, val_loss: 0.0849\n",
      "Epoch 32/50: train_loss: 0.0911, val_loss: 0.0799\n",
      "Epoch 33/50: train_loss: 0.0865, val_loss: 0.0837\n",
      "Epoch 34/50: train_loss: 0.0839, val_loss: 0.0738\n",
      "Epoch 35/50: train_loss: 0.0814, val_loss: 0.0713\n",
      "Epoch 36/50: train_loss: 0.0750, val_loss: 0.0709\n",
      "Epoch 37/50: train_loss: 0.0718, val_loss: 0.0682\n",
      "Epoch 38/50: train_loss: 0.0723, val_loss: 0.0624\n",
      "Epoch 39/50: train_loss: 0.0681, val_loss: 0.0645\n",
      "Epoch 40/50: train_loss: 0.0670, val_loss: 0.0577\n",
      "Epoch 41/50: train_loss: 0.0635, val_loss: 0.0608\n",
      "Epoch 42/50: train_loss: 0.0642, val_loss: 0.0581\n",
      "Epoch 43/50: train_loss: 0.0625, val_loss: 0.0592\n",
      "Epoch 44/50: train_loss: 0.0615, val_loss: 0.0527\n",
      "Epoch 45/50: train_loss: 0.0573, val_loss: 0.0521\n",
      "Epoch 46/50: train_loss: 0.0579, val_loss: 0.0505\n",
      "Epoch 47/50: train_loss: 0.0564, val_loss: 0.0563\n",
      "Epoch 48/50: train_loss: 0.0562, val_loss: 0.0505\n",
      "Epoch 49/50: train_loss: 0.0535, val_loss: 0.0503\n",
      "Epoch 50/50: train_loss: 0.0535, val_loss: 0.0475\n"
     ]
    }
   ],
   "source": [
    "# Train the linear model and plot how the loss changes as the \n",
    "# training progresses for both training and validation set.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, validation_loader, optimizer, 50, criterion, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74. 76. 74. 77.]\n",
      " [72. 70. 72. 71.]\n",
      " [69. 74. 69. 74.]\n",
      " [70. 69. 70. 69.]\n",
      " [75. 75. 76. 75.]\n",
      " [76. 77. 75. 75.]\n",
      " [73. 66. 73. 66.]\n",
      " [74. 69. 74. 68.]\n",
      " [75. 77. 75. 77.]\n",
      " [67. 74. 67. 73.]\n",
      " [73. 74. 73. 74.]\n",
      " [66. 64. 66. 64.]\n",
      " [72. 71. 72. 72.]\n",
      " [71. 69. 71. 70.]\n",
      " [67. 72. 67. 70.]\n",
      " [68. 69. 69. 69.]\n",
      " [75. 75. 74. 74.]\n",
      " [71. 71. 71. 71.]\n",
      " [77. 76. 77. 75.]\n",
      " [73. 74. 73. 75.]\n",
      " [74. 72. 73. 72.]\n",
      " [74. 72. 73. 72.]\n",
      " [70. 72. 69. 73.]\n",
      " [66. 64. 67. 66.]\n",
      " [73. 69. 72. 70.]\n",
      " [69. 70. 69. 70.]\n",
      " [73. 71. 74. 71.]\n",
      " [70. 69. 69. 69.]\n",
      " [71. 69. 71. 69.]\n",
      " [74. 75. 74. 75.]\n",
      " [69. 69. 68. 69.]\n",
      " [67. 69. 67. 70.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check predictions from samples\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = model(x)  # predict output from input\n",
    "    \n",
    "    scaled_y = label_scaler.inverse_transform(y.detach().numpy())\n",
    "    scaled_output = label_scaler.inverse_transform(output.detach().numpy())\n",
    "\n",
    "    print(np.concatenate((scaled_y, np.round(scaled_output)), axis=1))\n",
    "    break\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "x = range(len(train_losses))\n",
    "plt.plot(x, train_losses, x, val_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72. 70. 72. 74. 72. 70. 69. 70. 72. 70. 69. 67. 67. 72. 71. 72. 74. 72.\n",
      " 70. 69. 67. 65. 65. 70. 72. 74. 71. 70. 69. 68. 70. 69. 67. 70. 72. 71.\n",
      " 70. 69. 67. 68. 67. 68. 69. 70. 69. 70. 71. 69. 68. 68. 68. 68. 69. 68.\n",
      " 69. 70. 70. 70. 69. 67. 67. 70. 71. 72. 71. 69. 68. 69. 69. 70. 69. 68.\n",
      " 69. 69. 70. 72. 72. 71. 69. 68.]\n"
     ]
    }
   ],
   "source": [
    "# predict midi from init samples\n",
    "\n",
    "init_index = 1000\n",
    "\n",
    "generated_track = train_dataset[init_index][0].clone()\n",
    "\n",
    "# predict for a certain length\n",
    "predict_length = 30  # TODO: Model the end of the songs as well through a terminator.\n",
    "\n",
    "x, y = train_dataset[init_index]\n",
    "x = x.to(device)\n",
    "for i in range(predict_length):\n",
    "    _, y = train_dataset[init_index + i]\n",
    "    y = y.to(device)\n",
    "    output = model(x)  # predict output from input\n",
    "    x = torch.cat((x[output.shape[0]:], output))  # shift the input by one by adding the prediction\n",
    "    generated_track = torch.cat((generated_track, output))  # append prediction to generated track\n",
    "    \n",
    "#print(generated_track.detach().numpy())\n",
    "    \n",
    "n_generated_track = generated_track.detach().numpy()\n",
    "n_generated_track = n_generated_track.reshape(int(n_generated_track.shape[0]/output.shape[0]), output.shape[0])\n",
    "track = label_scaler.inverse_transform(n_generated_track).round().flatten()\n",
    "\n",
    "print(track)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write numpy to midi track\n",
    "\n",
    "numpy_notes = midi_utils.prediction_to_numpy(track, 1024)\n",
    "\n",
    "# create midi track\n",
    "new_track = midi_utils.numpy_to_midi_track(numpy_notes, 1, 'Modified')\n",
    "\n",
    "#print(numpy_notes)\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "# make new song with the new track\n",
    "new_track_dict = {}\n",
    "new_track_dict['0'] = track_dict['0']\n",
    "new_track_dict['1'] = new_track\n",
    "modified_midi_filename = 'midi_data/test_modified_track.mid'\n",
    "modified_csv_list = midi_utils.track_dict_to_csv(new_track_dict)\n",
    "midi_utils.write_to_midi(modified_csv_list, modified_midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "pygame.mixer.music.load(modified_midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
