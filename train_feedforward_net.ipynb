{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train feedforward net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import src.midi_utils as midi_utils\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_filename = 'midi_data/bwv104.6.mid'\n",
    "#midi_filename = 'midi_data/pkgsc_azalea.mid'\n",
    "pygame.init()\n",
    "pygame.mixer.music.load(midi_filename)\n",
    "pygame.mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "17204\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "soprano_tracks = []\n",
    "# iterate over all midi files of folder\n",
    "import glob, os\n",
    "\n",
    "#os.chdir(\"./midi_data/bach\")\n",
    "for midi_file in glob.glob(\"*.mid\"):\n",
    "    # get a list of all soprano tracks\n",
    "    ## load midi file\n",
    "    csv_text = midi_utils.load_to_csv(midi_file)\n",
    "\n",
    "    ## Split into tracks\n",
    "    track_dict = midi_utils.split_tracks(csv_text)\n",
    "    track_nr = '1'\n",
    "\n",
    "    ## Generating numpy array with notes\n",
    "    track = midi_utils.midi_track_to_numpy(track_dict[track_nr])\n",
    "    soprano_tracks.append(track)\n",
    "    \n",
    "print(len(soprano_tracks))\n",
    "\n",
    "x, y = get_dataset_representation_from_tracks(soprano_tracks)\n",
    "\n",
    "print(len(x))\n",
    "\n",
    "mini_batch_size = 32\n",
    "\n",
    "train_dataset = TrackDataset(x, y)  # make training dataset\n",
    "#validation_dataset = TrackDataset(val_images, val_centers)  # make validation dataset\n",
    "#test_dataset = TrackDataset(test_images, test_centers)  # make test dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True) # TODO TODO TODO: CHANGE TO A SUITABLE VALIDATIONSET\n",
    "#test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 17204\n",
      "Input size 10/ output size 1/ learning rate 0.0001\n",
      "Input example tensor([74., 77., 74., 74., 74., 74., 75., 74., 72., 72.])\n",
      "Output example tensor([70.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "print(\"Training set size\", len(train_dataset))\n",
    "\n",
    "input_size = len(train_dataset[0][0])  # get input size\n",
    "input_example = train_dataset[0][0]\n",
    "output_size = len(train_dataset[0][1])  # get output size\n",
    "output_example = train_dataset[0][1]\n",
    "learning_rate = 0.0001\n",
    "\n",
    "print(\"Input size {}/ output size {}/ learning rate {}\".format(input_size, output_size, learning_rate))\n",
    "print(\"Input example {}\".format(input_example))\n",
    "print(\"Output example {}\".format(output_example))\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_dimension, output_dimension, bias=True)  # linear layer with parameters A, b\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = self.fc(input_data)  # applies out = input * A + b. A, b are parameters of nn.Linear that we want to learn\n",
    "        return output\n",
    "    \n",
    "class MLPModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.layers(input)\n",
    "    \n",
    "device=torch.device('cpu')\n",
    "    \n",
    "linear_model = LinearModel(input_size, output_size)\n",
    "\n",
    "linear_model = mlp_model.to(device)\n",
    "\n",
    "mlp_model = MLPModel(input_size, 64, output_size)\n",
    "\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(mlp_model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device=torch.device('cpu'), verbose=1):\n",
    "    # We will monitor loss functions as the training progresses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # training phase\n",
    "        model.train()\n",
    "        # Iterate mini batches over training dataset\n",
    "        losses = []\n",
    "        for x, y in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)  # predict output from input\n",
    "            \n",
    "            # set gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            if verbose > 2:\n",
    "                print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        # iterate mini batches over validation set\n",
    "        # We don't need gradients\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "                loss = loss_function(output, y)\n",
    "                if verbose > 1:\n",
    "                    print(loss.item())\n",
    "\n",
    "                losses.append(loss.item())\n",
    "        val_losses.append(np.mean(np.array(losses)))\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Epoch {}/{}: train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, n_epochs, train_losses[-1], val_losses[-1]))\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: train_loss: 435.1733, val_loss: 391.2992\n",
      "Epoch 2/100: train_loss: 353.3543, val_loss: 317.9706\n",
      "Epoch 3/100: train_loss: 287.4284, val_loss: 258.8635\n",
      "Epoch 4/100: train_loss: 234.1787, val_loss: 211.1693\n",
      "Epoch 5/100: train_loss: 191.3070, val_loss: 172.7685\n",
      "Epoch 6/100: train_loss: 156.7170, val_loss: 141.7183\n",
      "Epoch 7/100: train_loss: 128.8058, val_loss: 116.7646\n",
      "Epoch 8/100: train_loss: 106.3203, val_loss: 96.5910\n",
      "Epoch 9/100: train_loss: 88.2039, val_loss: 80.3473\n",
      "Epoch 10/100: train_loss: 73.5825, val_loss: 67.2614\n",
      "Epoch 11/100: train_loss: 61.7957, val_loss: 56.6769\n",
      "Epoch 12/100: train_loss: 52.2798, val_loss: 48.1663\n",
      "Epoch 13/100: train_loss: 44.6057, val_loss: 41.2959\n",
      "Epoch 14/100: train_loss: 38.4302, val_loss: 35.7494\n",
      "Epoch 15/100: train_loss: 33.4383, val_loss: 31.2943\n",
      "Epoch 16/100: train_loss: 29.4284, val_loss: 27.6800\n",
      "Epoch 17/100: train_loss: 26.1830, val_loss: 24.7800\n",
      "Epoch 18/100: train_loss: 23.5666, val_loss: 22.4401\n",
      "Epoch 19/100: train_loss: 21.4653, val_loss: 20.5510\n",
      "Epoch 20/100: train_loss: 19.7657, val_loss: 19.0263\n",
      "Epoch 21/100: train_loss: 18.3984, val_loss: 17.8026\n",
      "Epoch 22/100: train_loss: 17.2865, val_loss: 16.8108\n",
      "Epoch 23/100: train_loss: 16.3931, val_loss: 16.0095\n",
      "Epoch 24/100: train_loss: 15.6776, val_loss: 15.3662\n",
      "Epoch 25/100: train_loss: 15.0939, val_loss: 14.8545\n",
      "Epoch 26/100: train_loss: 14.6323, val_loss: 14.4354\n",
      "Epoch 27/100: train_loss: 14.2539, val_loss: 14.0910\n",
      "Epoch 28/100: train_loss: 13.9514, val_loss: 13.8208\n",
      "Epoch 29/100: train_loss: 13.7047, val_loss: 13.5960\n",
      "Epoch 30/100: train_loss: 13.5062, val_loss: 13.4208\n",
      "Epoch 31/100: train_loss: 13.3489, val_loss: 13.2857\n",
      "Epoch 32/100: train_loss: 13.2249, val_loss: 13.1648\n",
      "Epoch 33/100: train_loss: 13.1214, val_loss: 13.0710\n",
      "Epoch 34/100: train_loss: 13.0325, val_loss: 12.9989\n",
      "Epoch 35/100: train_loss: 12.9635, val_loss: 12.9414\n",
      "Epoch 36/100: train_loss: 12.9113, val_loss: 12.8890\n",
      "Epoch 37/100: train_loss: 12.8709, val_loss: 12.8494\n",
      "Epoch 38/100: train_loss: 12.8372, val_loss: 12.8199\n",
      "Epoch 39/100: train_loss: 12.8030, val_loss: 12.7941\n",
      "Epoch 40/100: train_loss: 12.7850, val_loss: 12.7696\n",
      "Epoch 41/100: train_loss: 12.7620, val_loss: 12.7577\n",
      "Epoch 42/100: train_loss: 12.7450, val_loss: 12.7418\n",
      "Epoch 43/100: train_loss: 12.7357, val_loss: 12.7299\n",
      "Epoch 44/100: train_loss: 12.7268, val_loss: 12.7207\n",
      "Epoch 45/100: train_loss: 12.7190, val_loss: 12.7164\n",
      "Epoch 46/100: train_loss: 12.7149, val_loss: 12.7075\n",
      "Epoch 47/100: train_loss: 12.7082, val_loss: 12.7041\n",
      "Epoch 48/100: train_loss: 12.7026, val_loss: 12.7008\n",
      "Epoch 49/100: train_loss: 12.6989, val_loss: 12.7004\n",
      "Epoch 50/100: train_loss: 12.6945, val_loss: 12.6944\n",
      "Epoch 51/100: train_loss: 12.6972, val_loss: 12.6933\n",
      "Epoch 52/100: train_loss: 12.6896, val_loss: 12.6918\n",
      "Epoch 53/100: train_loss: 12.6922, val_loss: 12.6957\n",
      "Epoch 54/100: train_loss: 12.6956, val_loss: 12.6919\n",
      "Epoch 55/100: train_loss: 12.6923, val_loss: 12.6869\n",
      "Epoch 56/100: train_loss: 12.6841, val_loss: 12.6888\n",
      "Epoch 57/100: train_loss: 12.6974, val_loss: 12.6859\n",
      "Epoch 58/100: train_loss: 12.6868, val_loss: 12.6895\n",
      "Epoch 59/100: train_loss: 12.6847, val_loss: 12.6878\n",
      "Epoch 60/100: train_loss: 12.6840, val_loss: 12.6886\n",
      "Epoch 61/100: train_loss: 12.6909, val_loss: 12.6871\n",
      "Epoch 62/100: train_loss: 12.6834, val_loss: 12.6835\n",
      "Epoch 63/100: train_loss: 12.6850, val_loss: 12.6866\n",
      "Epoch 64/100: train_loss: 12.6930, val_loss: 12.6878\n",
      "Epoch 65/100: train_loss: 12.6861, val_loss: 12.6859\n",
      "Epoch 66/100: train_loss: 12.6901, val_loss: 12.6867\n",
      "Epoch 67/100: train_loss: 12.6835, val_loss: 12.6857\n",
      "Epoch 68/100: train_loss: 12.6852, val_loss: 12.6840\n",
      "Epoch 69/100: train_loss: 12.6877, val_loss: 12.6850\n",
      "Epoch 70/100: train_loss: 12.6906, val_loss: 12.6900\n",
      "Epoch 71/100: train_loss: 12.6886, val_loss: 12.6866\n",
      "Epoch 72/100: train_loss: 12.6884, val_loss: 12.6856\n",
      "Epoch 73/100: train_loss: 12.6860, val_loss: 12.6821\n",
      "Epoch 74/100: train_loss: 12.6857, val_loss: 12.6873\n",
      "Epoch 75/100: train_loss: 12.6854, val_loss: 12.6880\n",
      "Epoch 76/100: train_loss: 12.6898, val_loss: 12.6854\n",
      "Epoch 77/100: train_loss: 12.6836, val_loss: 12.6819\n",
      "Epoch 78/100: train_loss: 12.6866, val_loss: 12.6833\n",
      "Epoch 79/100: train_loss: 12.6865, val_loss: 12.6850\n",
      "Epoch 80/100: train_loss: 12.6854, val_loss: 12.6864\n",
      "Epoch 81/100: train_loss: 12.6839, val_loss: 12.6854\n",
      "Epoch 82/100: train_loss: 12.6867, val_loss: 12.6875\n",
      "Epoch 83/100: train_loss: 12.6850, val_loss: 12.6946\n",
      "Epoch 84/100: train_loss: 12.6892, val_loss: 12.6877\n",
      "Epoch 85/100: train_loss: 12.6882, val_loss: 12.6851\n",
      "Epoch 86/100: train_loss: 12.6888, val_loss: 12.6886\n",
      "Epoch 87/100: train_loss: 12.6852, val_loss: 12.6896\n",
      "Epoch 88/100: train_loss: 12.6851, val_loss: 12.6857\n",
      "Epoch 89/100: train_loss: 12.6907, val_loss: 12.6833\n",
      "Epoch 90/100: train_loss: 12.6885, val_loss: 12.6830\n",
      "Epoch 91/100: train_loss: 12.6859, val_loss: 12.6879\n",
      "Epoch 92/100: train_loss: 12.6835, val_loss: 12.6854\n",
      "Epoch 93/100: train_loss: 12.6899, val_loss: 12.6875\n",
      "Epoch 94/100: train_loss: 12.6844, val_loss: 12.6824\n",
      "Epoch 95/100: train_loss: 12.6835, val_loss: 12.6872\n",
      "Epoch 96/100: train_loss: 12.6851, val_loss: 12.6856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8abda744109b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-c49d358f74b5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device, verbose)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\i0325777\\appdata\\local\\continuum\\miniconda3\\envs\\tensorflow-base\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the linear model and plot how the loss changes as the \n",
    "# training progresses for both training and validation set.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_losses, val_losses = train(mlp_model, train_loader, validation_loader, optimizer, 100, criterion, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[70., 69., 67., 65., 69., 67., 65., 72., 72., 71.],\n",
      "        [71., 71., 76., 75., 76., 78., 76., 74., 73., 71.],\n",
      "        [72., 74., 74., 75., 72., 74., 70., 72., 74., 75.],\n",
      "        [78., 78., 76., 74., 73., 71., 73., 69., 73., 74.],\n",
      "        [74., 72., 70., 74., 75., 77., 74., 75., 74., 74.],\n",
      "        [71., 72., 74., 72., 72., 71., 72., 74., 69., 71.],\n",
      "        [73., 71., 74., 73., 71., 76., 74., 73., 71., 69.],\n",
      "        [71., 69., 73., 74., 76., 76., 74., 73., 74., 76.],\n",
      "        [74., 75., 74., 72., 70., 74., 77., 75., 74., 67.],\n",
      "        [67., 69., 71., 71., 76., 75., 76., 78., 74., 73.],\n",
      "        [76., 69., 68., 66., 64., 66., 68., 69., 71., 73.],\n",
      "        [67., 71., 73., 74., 71., 76., 74., 73., 73., 71.],\n",
      "        [70., 69., 69., 69., 69., 69., 70., 70., 70., 69.],\n",
      "        [69., 69., 69., 71., 71., 69., 67., 66., 69., 69.],\n",
      "        [68., 69., 71., 69., 74., 74., 73., 74., 74., 73.],\n",
      "        [72., 70., 69., 67., 72., 74., 74., 69., 70., 72.],\n",
      "        [76., 74., 74., 73., 74., 74., 76., 78., 78., 76.],\n",
      "        [69., 68., 66., 71., 71., 69., 68., 66., 64., 66.],\n",
      "        [74., 76., 78., 79., 78., 78., 76., 78., 75., 75.],\n",
      "        [67., 69., 70., 69., 67., 65., 72., 74., 72., 67.],\n",
      "        [71., 73., 74., 78., 76., 74., 76., 74., 72., 76.],\n",
      "        [74., 76., 77., 74., 72., 70., 69., 67., 69., 67.],\n",
      "        [69., 71., 69., 74., 74., 73., 74., 74., 73., 71.],\n",
      "        [72., 71., 72., 74., 72., 71., 69., 69., 64., 69.],\n",
      "        [72., 74., 72., 71., 69., 67., 71., 69., 62., 67.],\n",
      "        [67., 69., 67., 65., 64., 62., 61., 65., 64., 65.],\n",
      "        [72., 69., 71., 72., 74., 67., 69., 71., 72., 71.],\n",
      "        [74., 73., 74., 74., 73., 71., 76., 74., 73., 74.],\n",
      "        [74., 74., 74., 74., 76., 74., 72., 71., 71., 67.],\n",
      "        [73., 73., 78., 76., 74., 73., 78., 76., 74., 73.],\n",
      "        [65., 67., 69., 67., 72., 72., 71., 72., 72., 71.],\n",
      "        [73., 74., 71., 76., 75., 76., 78., 79., 78., 78.]])\n",
      "\n",
      "\n",
      "tensor([[72.],\n",
      "        [73.],\n",
      "        [77.],\n",
      "        [73.],\n",
      "        [72.],\n",
      "        [72.],\n",
      "        [71.],\n",
      "        [74.],\n",
      "        [69.],\n",
      "        [71.],\n",
      "        [74.],\n",
      "        [71.],\n",
      "        [69.],\n",
      "        [67.],\n",
      "        [71.],\n",
      "        [70.],\n",
      "        [74.],\n",
      "        [68.],\n",
      "        [76.],\n",
      "        [69.],\n",
      "        [74.],\n",
      "        [74.],\n",
      "        [76.],\n",
      "        [67.],\n",
      "        [72.],\n",
      "        [64.],\n",
      "        [69.],\n",
      "        [76.],\n",
      "        [69.],\n",
      "        [74.],\n",
      "        [69.],\n",
      "        [76.]])\n",
      "71.65625\n",
      "\n",
      "\n",
      "tensor([[70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010],\n",
      "        [70.6010]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    output = mlp_model(x)  # predict output from input\n",
    "\n",
    "    print(x)\n",
    "    print(\"\\n\")\n",
    "    print(y)\n",
    "    print(torch.mean(y).item())\n",
    "    print(\"\\n\")\n",
    "    print(output)\n",
    "    break\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "x = range(len(train_losses))\n",
    "plt.plot(x, train_losses, x, val_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy_notes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1b73070f00ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# write numpy to midi track\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_track\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmidi_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_to_midi_track\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy_notes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Modified'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrack_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_track\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodified_midi_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'midi_data/test_modified_track.mid'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy_notes' is not defined"
     ]
    }
   ],
   "source": [
    "# write numpy to midi track\n",
    "new_track = midi_utils.numpy_to_midi_track(numpy_notes, 1, 'Modified')\n",
    "\n",
    "track_dict['1'] = new_track\n",
    "modified_midi_filename = 'midi_data/test_modified_track.mid'\n",
    "modified_csv_list = midi_utils.track_dict_to_csv(track_dict)\n",
    "midi_utils.write_to_midi(modified_csv_list, modified_midi_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
