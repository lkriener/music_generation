{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_feedforward_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upMkQI5Ri8kU",
        "colab_type": "text"
      },
      "source": [
        "# Train feedforward net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeCTwk5i8kW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "71226a0a-e7b0-49fc-9fe0-c618ccc9170b"
      },
      "source": [
        "# Uncomment the line below and run this cell to get your data from github into colab (only runnable in colab, not ordinary jupyter notebook):\n",
        "! git clone https://github.com/lkriener/music_generation.git && mv music_generation/* . && rm music_generation -r"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'music_generation'...\n",
            "remote: Enumerating objects: 433, done.\u001b[K\n",
            "remote: Counting objects: 100% (433/433), done.\u001b[K\n",
            "remote: Compressing objects: 100% (411/411), done.\u001b[K\n",
            "remote: Total 433 (delta 33), reused 415 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (433/433), 309.67 KiB | 4.18 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PDGFwS8jKrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b7964db3-b3d8-4e4a-877e-69d1687f59f6"
      },
      "source": [
        "# Uncomment line to install requirements\n",
        "! pip install -r colab_requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame==1.9.6 (from -r colab_requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 3.4MB/s \n",
            "\u001b[?25hCollecting py_midicsv==1.9.0 (from -r colab_requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/eb/3133f65bd34dafcbae37508d290ebf540832430cbe2aef23629cc6a6197f/py_midicsv-1.9.0-py3-none-any.whl\n",
            "Installing collected packages: pygame, py-midicsv\n",
            "Successfully installed py-midicsv-1.9.0 pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz32cHiui8kb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f6b2ae5-5543-4ff8-cf7c-02a97cda8e59"
      },
      "source": [
        "import src.midi_utils as midi_utils\n",
        "\n",
        "import pygame"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SHyV0zBi8kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "56394c81-ac40-4b9c-af10-ad1ce23026ba"
      },
      "source": [
        "midi_filename = 'midi_data/bwv104.6.mid'\n",
        "# midi_filename = 'midi_data/pkgsc_azalea.mid'\n",
        "pygame.init()\n",
        "pygame.mixer.music.load(midi_filename)\n",
        "pygame.mixer.music.play()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2e42cb071a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# midi_filename = 'midi_data/pkgsc_azalea.mid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: mixer not initialized"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH3jo86Qi8kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pygame.mixer.music.stop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8Q3soTTi8km",
        "colab_type": "text"
      },
      "source": [
        "# Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxMigMtRi8km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bcb853a6-7d49-4fcc-83de-8b3cedbb3165"
      },
      "source": [
        "from src.dataset_utils import TrackDataset, get_dataset_representation_from_tracks\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "feature_scaler = StandardScaler()\n",
        "label_scaler = StandardScaler()\n",
        "\n",
        "tracks = []\n",
        "# iterate over all midi files of folder\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    home_dir\n",
        "except NameError:\n",
        "    home_dir = os.getcwd()\n",
        "\n",
        "os.chdir(home_dir + \"/midi_data/bach\")  # go to a folder relative to home dir\n",
        "for midi_file in glob.glob(\"*.mid\"):\n",
        "    # get a list of all soprano tracks\n",
        "    ## load midi file\n",
        "    csv_text = midi_utils.load_to_csv(midi_file)\n",
        "\n",
        "    ## Split into tracks\n",
        "    track_dict = midi_utils.split_tracks(csv_text)\n",
        "    track_nr = '1'\n",
        "\n",
        "    ## Generating numpy array with notes\n",
        "    track = midi_utils.midi_track_to_numpy(track_dict[track_nr])\n",
        "    tracks.append(track)\n",
        "    \n",
        "print(\"Number of tracks: \" + str(len(tracks)))\n",
        "\n",
        "x, y = get_dataset_representation_from_tracks(tracks, feature_qty=20, prediction_qty=2)\n",
        "\n",
        "# drop length of notes and keep pitch\n",
        "x = np.stack(x)\n",
        "x = x[:,:,0]\n",
        "\n",
        "y = np.stack(y)\n",
        "y = y[:,:,0]\n",
        "\n",
        "feature_scaler.fit(x)\n",
        "\n",
        "print(\"Mean of the dataset: \" + str(feature_scaler.mean_[0]))\n",
        "\n",
        "x = feature_scaler.fit_transform(x)\n",
        "\n",
        "label_scaler.fit(y)\n",
        "\n",
        "y = label_scaler.fit_transform(y)\n",
        "\n",
        "print(\"Number of samples: \" + str(len(x)))\n",
        "\n",
        "mini_batch_size = 32\n",
        "\n",
        "# for now, we only train on the pitches of the notes\n",
        "train_dataset = TrackDataset(x, y, drop_length=False)  # make training dataset\n",
        "#validation_dataset = TrackDataset(val_images, val_centers)  # make validation dataset\n",
        "#test_dataset = TrackDataset(test_images, test_centers)  # make test dataset\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True) # TODO TODO TODO: CHANGE TO A SUITABLE VALIDATIONSET\n",
        "#test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tracks: 357\n",
            "Mean of the dataset: 70.56518791895759\n",
            "Number of samples: 13277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVgPaaAUi8kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d90aa1c7-7443-4d75-d481-84a73d50deea"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "print(\"Training set size\", len(train_dataset))\n",
        "\n",
        "input_size = len(train_dataset[0][0])  # get input size\n",
        "input_example = train_dataset[0][0]\n",
        "output_size = len(train_dataset[0][1])  # get output size\n",
        "output_example = train_dataset[0][1]\n",
        "learning_rate = 0.001\n",
        "\n",
        "print(\"Input size {}/ output size {}/ learning rate {}\".format(input_size, output_size, learning_rate))\n",
        "print(\"Input example {}\".format(input_example))\n",
        "print(\"Output example {}\".format(output_example))\n",
        "\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dimension, output_dimension):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.fc = torch.nn.Linear(input_dimension, output_dimension, bias=True)  # linear layer with parameters A, b\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        output = self.fc(input_data)  # applies out = input * A + b. A, b are parameters of nn.Linear that we want to learn\n",
        "        return output\n",
        "    \n",
        "\n",
        "class MLPModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.layers(input)\n",
        "    \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "# linear_model = LinearModel(input_size, output_size)\n",
        "# \n",
        "# linear_model = linear_model.to(device)\n",
        "# \n",
        "mlp_model = MLPModel(input_size, 256, output_size)\n",
        "\n",
        "mlp_model = mlp_model.to(device)\n",
        "\n",
        "model = mlp_model\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, optimizer, n_epochs, loss_function, device=torch.device('cpu'), verbose=1):\n",
        "    # We will monitor loss functions as the training progresses\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # training phase\n",
        "        model.train()\n",
        "        # Iterate mini batches over training dataset\n",
        "        losses = []\n",
        "        for x, y in train_dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x)  # predict output from input\n",
        "            \n",
        "            # set gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = loss_function(output, y)\n",
        "            if verbose > 2:\n",
        "                print(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Metrics\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "        train_losses.append(np.mean(np.array(losses)))\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        # iterate mini batches over validation set\n",
        "        # We don't need gradients\n",
        "        losses = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_dataloader:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                output = model(x)\n",
        "                loss = loss_function(output, y)\n",
        "                if verbose > 1:\n",
        "                    print(loss.item())\n",
        "\n",
        "                losses.append(loss.item())\n",
        "        val_losses.append(np.mean(np.array(losses)))\n",
        "        \n",
        "        if verbose > 0:\n",
        "            print('Epoch {}/{}: train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, n_epochs, train_losses[-1], val_losses[-1]))\n",
        "    return train_losses, val_losses\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size 13277\n",
            "Input size 20/ output size 2/ learning rate 0.001\n",
            "Input example tensor([ 0.4092, -1.0379, -0.4763,  0.0869,  0.3654,  0.3650, -1.0497,  0.3694,\n",
            "        -0.1949, -0.4756, -1.0335, -1.0291, -0.4635, -0.1782,  0.3826, -0.1802,\n",
            "        -0.4623, -1.0242, -1.0283,  0.3707])\n",
            "Output example tensor([0.3758, 0.1106])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKXI2Xyi8kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "baa50a74-5f1a-45be-fa73-5cb6d606d76c"
      },
      "source": [
        "# Train the linear model and plot how the loss changes as the \n",
        "# training progresses for both training and validation set.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "train_losses, val_losses = train(model, train_loader, validation_loader, optimizer, 50, criterion, device=device, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50: train_loss: 0.5324, val_loss: 0.5081\n",
            "Epoch 2/50: train_loss: 0.4992, val_loss: 0.4839\n",
            "Epoch 3/50: train_loss: 0.4893, val_loss: 0.4642\n",
            "Epoch 4/50: train_loss: 0.4759, val_loss: 0.4587\n",
            "Epoch 5/50: train_loss: 0.4663, val_loss: 0.4361\n",
            "Epoch 6/50: train_loss: 0.4505, val_loss: 0.4230\n",
            "Epoch 7/50: train_loss: 0.4361, val_loss: 0.4079\n",
            "Epoch 8/50: train_loss: 0.4179, val_loss: 0.3850\n",
            "Epoch 9/50: train_loss: 0.4012, val_loss: 0.3581\n",
            "Epoch 10/50: train_loss: 0.3818, val_loss: 0.3518\n",
            "Epoch 11/50: train_loss: 0.3623, val_loss: 0.3299\n",
            "Epoch 12/50: train_loss: 0.3426, val_loss: 0.3083\n",
            "Epoch 13/50: train_loss: 0.3190, val_loss: 0.2945\n",
            "Epoch 14/50: train_loss: 0.3031, val_loss: 0.2714\n",
            "Epoch 15/50: train_loss: 0.2805, val_loss: 0.2539\n",
            "Epoch 16/50: train_loss: 0.2608, val_loss: 0.2245\n",
            "Epoch 17/50: train_loss: 0.2418, val_loss: 0.2098\n",
            "Epoch 18/50: train_loss: 0.2250, val_loss: 0.2055\n",
            "Epoch 19/50: train_loss: 0.2070, val_loss: 0.1741\n",
            "Epoch 20/50: train_loss: 0.1907, val_loss: 0.1719\n",
            "Epoch 21/50: train_loss: 0.1787, val_loss: 0.1538\n",
            "Epoch 22/50: train_loss: 0.1645, val_loss: 0.1499\n",
            "Epoch 23/50: train_loss: 0.1538, val_loss: 0.1359\n",
            "Epoch 24/50: train_loss: 0.1404, val_loss: 0.1340\n",
            "Epoch 25/50: train_loss: 0.1306, val_loss: 0.1168\n",
            "Epoch 26/50: train_loss: 0.1229, val_loss: 0.1079\n",
            "Epoch 27/50: train_loss: 0.1146, val_loss: 0.0992\n",
            "Epoch 28/50: train_loss: 0.1096, val_loss: 0.0938\n",
            "Epoch 29/50: train_loss: 0.0995, val_loss: 0.0924\n",
            "Epoch 30/50: train_loss: 0.0965, val_loss: 0.0858\n",
            "Epoch 31/50: train_loss: 0.0951, val_loss: 0.0812\n",
            "Epoch 32/50: train_loss: 0.0903, val_loss: 0.0815\n",
            "Epoch 33/50: train_loss: 0.0842, val_loss: 0.0754\n",
            "Epoch 34/50: train_loss: 0.0801, val_loss: 0.0760\n",
            "Epoch 35/50: train_loss: 0.0770, val_loss: 0.0685\n",
            "Epoch 36/50: train_loss: 0.0720, val_loss: 0.0664\n",
            "Epoch 37/50: train_loss: 0.0708, val_loss: 0.0662\n",
            "Epoch 38/50: train_loss: 0.0690, val_loss: 0.0607\n",
            "Epoch 39/50: train_loss: 0.0659, val_loss: 0.0627\n",
            "Epoch 40/50: train_loss: 0.0644, val_loss: 0.0561\n",
            "Epoch 41/50: train_loss: 0.0626, val_loss: 0.0572\n",
            "Epoch 42/50: train_loss: 0.0598, val_loss: 0.0540\n",
            "Epoch 43/50: train_loss: 0.0594, val_loss: 0.0544\n",
            "Epoch 44/50: train_loss: 0.0585, val_loss: 0.0514\n",
            "Epoch 45/50: train_loss: 0.0573, val_loss: 0.0524\n",
            "Epoch 46/50: train_loss: 0.0539, val_loss: 0.0474\n",
            "Epoch 47/50: train_loss: 0.0547, val_loss: 0.0523\n",
            "Epoch 48/50: train_loss: 0.0545, val_loss: 0.0575\n",
            "Epoch 49/50: train_loss: 0.0533, val_loss: 0.0450\n",
            "Epoch 50/50: train_loss: 0.0489, val_loss: 0.0448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkFD6gaEi8kx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "0586225e-a86d-4b94-eae0-c5cf6abfa70a"
      },
      "source": [
        "# check predictions from samples\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for x, y in train_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    output = model(x)  # predict output from input\n",
        "    \n",
        "    scaled_y = label_scaler.inverse_transform(y.cpu().detach().numpy())\n",
        "    scaled_output = label_scaler.inverse_transform(output.cpu().detach().numpy())\n",
        "\n",
        "    print(np.concatenate((scaled_y, np.round(scaled_output)), axis=1))\n",
        "    break\n",
        "\n",
        "\n",
        "plt.axis('on')\n",
        "x = range(len(train_losses))\n",
        "plt.plot(x, train_losses, x, val_losses)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67. 65. 68. 67.]\n",
            " [66. 67. 66. 67.]\n",
            " [68. 70. 67. 70.]\n",
            " [74. 71. 74. 72.]\n",
            " [69. 71. 68. 71.]\n",
            " [71. 72. 71. 72.]\n",
            " [69. 71. 68. 70.]\n",
            " [74. 76. 75. 75.]\n",
            " [72. 70. 71. 69.]\n",
            " [68. 69. 69. 69.]\n",
            " [72. 71. 72. 71.]\n",
            " [67. 69. 67. 67.]\n",
            " [72. 74. 72. 74.]\n",
            " [70. 74. 70. 74.]\n",
            " [67. 70. 68. 70.]\n",
            " [76. 74. 75. 74.]\n",
            " [70. 69. 70. 69.]\n",
            " [71. 72. 71. 72.]\n",
            " [68. 69. 68. 68.]\n",
            " [72. 74. 72. 73.]\n",
            " [72. 69. 73. 69.]\n",
            " [68. 67. 68. 66.]\n",
            " [73. 71. 73. 71.]\n",
            " [66. 64. 66. 65.]\n",
            " [65. 64. 64. 62.]\n",
            " [70. 69. 71. 69.]\n",
            " [73. 71. 73. 71.]\n",
            " [70. 69. 70. 69.]\n",
            " [72. 70. 73. 70.]\n",
            " [65. 67. 64. 67.]\n",
            " [72. 72. 72. 72.]\n",
            " [74. 72. 76. 73.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUmO/Sw//AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsW176Y2i8k1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ae7a531d-f0d7-4ad8-d7cb-3d1bf963f78d"
      },
      "source": [
        "# predict midi from init samples\n",
        "\n",
        "init_index = 1000\n",
        "\n",
        "generated_track = train_dataset[init_index][0].clone().to(device)\n",
        "\n",
        "# predict for a certain length\n",
        "predict_length = 30  # TODO: Model the end of the songs as well through a terminator.\n",
        "\n",
        "x, y = train_dataset[init_index]\n",
        "x = x.to(device)\n",
        "for i in range(predict_length):\n",
        "    _, y = train_dataset[init_index + i]\n",
        "    y = y.to(device)\n",
        "    output = model(x)  # predict output from input\n",
        "    x = torch.cat((x[output.shape[0]:], output))  # shift the input by one by adding the prediction\n",
        "    generated_track = torch.cat((generated_track, output))  # append prediction to generated track\n",
        "    \n",
        "#print(generated_track.detach().numpy())\n",
        "    \n",
        "n_generated_track = generated_track.cpu().detach().numpy()\n",
        "n_generated_track = n_generated_track.reshape(int(n_generated_track.shape[0]/output.shape[0]), output.shape[0])\n",
        "track = label_scaler.inverse_transform(n_generated_track).round().flatten()\n",
        "\n",
        "print(track)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[67. 72. 71. 69. 67. 67. 69. 71. 72. 71. 69. 64. 66. 67. 67. 67. 62. 67.\n",
            " 72. 71. 70. 68. 68. 70. 72. 72. 71. 69. 67. 66. 67. 65. 67. 69. 68. 72.\n",
            " 71. 70. 70. 67. 69. 69. 69. 70. 72. 74. 73. 73. 72. 71. 71. 71. 74. 73.\n",
            " 72. 71. 71. 69. 68. 71. 73. 73. 71. 69. 71. 69. 69. 69. 68. 68. 69. 71.\n",
            " 71. 71. 70. 69. 69. 71. 72. 75.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSyiG-4Ni8k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write numpy to midi track\n",
        "\n",
        "numpy_notes = midi_utils.prediction_to_numpy(track, 1024)\n",
        "\n",
        "# create midi track\n",
        "new_track = midi_utils.numpy_to_midi_track(numpy_notes, 1, 'Modified')\n",
        "\n",
        "#print(numpy_notes)\n",
        "\n",
        "os.chdir(home_dir)\n",
        "\n",
        "# make new song with the new track\n",
        "new_track_dict = {}\n",
        "new_track_dict['0'] = track_dict['0']\n",
        "new_track_dict['1'] = new_track\n",
        "modified_midi_filename = 'results/feedforward_net_track.mid'\n",
        "modified_csv_list = midi_utils.track_dict_to_csv(new_track_dict)\n",
        "midi_utils.write_to_midi(modified_csv_list, modified_midi_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZCj7Wyi8k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pygame.init()\n",
        "pygame.mixer.music.load(modified_midi_filename)\n",
        "pygame.mixer.music.play()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpfqnFH8i8k-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pygame.mixer.music.stop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfvEB29Ni8lA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "957b2c87-1554-4505-8f8d-e82acc75fbda"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxwPzweyS2Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}